{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import pandas as pd\n",
    "import json\n",
    "import codecs\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def read_dataset(path):\n",
    "  with codecs.open(path, 'r', 'utf-8') as myFile:\n",
    "    content = myFile.read()\n",
    "  dataset = json.loads(content)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5671\n",
      "Data loading and train-test splits = DONE!\n"
     ]
    }
   ],
   "source": [
    "###load JSON file\n",
    "file_name = 'data/pizza_request_dataset.json'\n",
    "dataset = read_dataset(file_name)\n",
    "df = pd.read_json(json.dumps(dataset, sort_keys=True, indent=2))\n",
    "\n",
    "###create random 90-10 split\n",
    "X = df\n",
    "print len(X)\n",
    "\n",
    "rows = random.sample(X.index, int(0.9*len(X)) + 1)\n",
    "X_train = X.ix[rows]\n",
    "X_test = X.drop(rows)\n",
    "y_train = X_train.requester_received_pizza.astype(int)\n",
    "y_test = X_test.requester_received_pizza.astype(int)\n",
    "\n",
    "print \"Data loading and train-test splits = DONE!\"\n",
    "###\n",
    "\n",
    "###subsample data\n",
    "# print \"Subsampling\"\n",
    "# subsample = 30\n",
    "# X_train, y_train, X_test, y_test = X_train[:subsample], y_train[:subsample], X_test[:subsample], y_test[:subsample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 1\n"
     ]
    }
   ],
   "source": [
    "print \"part 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting part 1!\n",
      "0.804395604396 0.847222222222 0.825253664036 0.726631393298\n",
      "ROC =  0.621416323731\n",
      "Specificity:  0.340740740741\n"
     ]
    }
   ],
   "source": [
    "###Model 1 - a) n-grams\n",
    "\n",
    "### build pipeline; fit train; predict on test\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "##vectorizer arguments blah!\n",
    "\n",
    "tokenizer=None#word_tokenize\n",
    "# stop_words=nltk.corpus.stopwords.words(\"english\")#None\n",
    "ngram_range=(1, 2)\n",
    "lowercase=True\n",
    "max_features=500\n",
    "binary=False\n",
    "dtype=np.float64\n",
    "\n",
    "class TextExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.vars]  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "\n",
    "###create unigram vectorizer\n",
    "uniVect = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(1,1),\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=max_features)\n",
    "\n",
    "###create bigram vect\n",
    "biVect = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(2,2),\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=max_features)\n",
    "\n",
    "# load custom features and FeatureUnion with Vectorizer\n",
    "features = []\n",
    "features.append(('unigram', uniVect))\n",
    "features.append(('bigram', biVect))\n",
    "all_features = FeatureUnion(features)\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('getText', TextExtractor('request_text_edit_aware')),\n",
    "                     ('all', all_features),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', linear_svc),\n",
    "                    ('clf', MultinomialNB(alpha=0.1)),\n",
    "\n",
    "                    ])\n",
    "\n",
    "# text_clf = Pipeline([\n",
    "#                      ('vect', vectorizer),\n",
    "# #                      ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', linear_svc),\n",
    "#                     ])\n",
    "\n",
    "###fit training data\n",
    "print \"Fitting part 1!\"\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n",
    "# print \"NO!\"\n",
    "probas = text_clf.predict_proba(X_test)\n",
    "# print \"YO!\"\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=0)\n",
    "print precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# roc_auc = roc_auc_score(y_test, predicted)\n",
    "roc_auc = roc_auc_score(y_test, probas[:,1])\n",
    "print \"ROC = \", roc_auc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test, predicted)\n",
    "#true negatives C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}\n",
    "tn = C[0][0]\n",
    "fn = C[1][0]\n",
    "tp = C[1][1]\n",
    "fp = C[0][1]\n",
    "##since labels are switched, invert the confusion matrix outputs: Pos = 0, Neg = 1\n",
    "#specificity = TN/TN+FP = tp/tp+fn\n",
    " \n",
    "print \"Specificity: \", float(tp)/(tp+fn)\n",
    "# print \"Precision: \", float(tn)/(tn+fn)\n",
    "# print \"Recall: \", float(tn)/(tn+fp)\n",
    "# print \"Accuracy: \", float(tn+tp)/(tn+tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 2\n"
     ]
    }
   ],
   "source": [
    "print \"part 2\"\n",
    "# 0.8125 0.854875283447 0.833149171271 0.733686067019\n",
    "# ROC =  0.563033149768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting part 2!\n",
      "0.995316159251 0.983796296296 0.989522700815 0.984126984127\n",
      "ROC =  0.621416323731\n",
      "Specificity:  0.985185185185\n"
     ]
    }
   ],
   "source": [
    "###Model 2 - a) custom features\n",
    "\n",
    "### build pipeline; fit train; predict on test\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing.data import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "class ColumnExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.vars]  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "    \n",
    "class StringExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.vars].astype(str)  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "    \n",
    "class SubredditExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.vars].apply(lambda x: ' '.join(x))  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "\n",
    "##vectorizer arguments blah!\n",
    "tokenizer=None#word_tokenize\n",
    "# stop_words=nltk.corpus.stopwords.words(\"english\")#None\n",
    "ngram_range=(1, 1)\n",
    "lowercase=True\n",
    "max_features=10000\n",
    "binary=False\n",
    "dtype=np.float64\n",
    "###create unigram vectorizer\n",
    "subVect = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=ngram_range,\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=max_features)\n",
    "\n",
    "flairVect = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=ngram_range,\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=100)\n",
    "\n",
    "# load custom features for FeatureUnion\n",
    "cols_act = [\n",
    "'post_was_edited',\n",
    "'requester_account_age_in_days_at_request',\n",
    "'requester_account_age_in_days_at_retrieval',\n",
    "'requester_days_since_first_post_on_raop_at_request',\n",
    "'requester_days_since_first_post_on_raop_at_retrieval',\n",
    "'requester_number_of_comments_at_request',\n",
    "'requester_number_of_comments_at_retrieval',\n",
    "'requester_number_of_comments_in_raop_at_request',\n",
    "'requester_number_of_comments_in_raop_at_retrieval',\n",
    "'requester_number_of_posts_at_request',\n",
    "'requester_number_of_posts_at_retrieval',\n",
    "'requester_number_of_posts_on_raop_at_request',\n",
    "'requester_number_of_posts_on_raop_at_retrieval',\n",
    "'requester_number_of_subreddits_at_request',\n",
    "# 'requester_subreddits_at_request',\n",
    "]\n",
    "\n",
    "cols_rep = [\n",
    "'number_of_downvotes_of_request_at_retrieval',\n",
    "'number_of_upvotes_of_request_at_retrieval',\n",
    "'requester_upvotes_minus_downvotes_at_request', ###this contains negative values\n",
    "'requester_upvotes_minus_downvotes_at_retrieval',###this contains negative values\n",
    "'requester_upvotes_plus_downvotes_at_request',\n",
    "'requester_upvotes_plus_downvotes_at_retrieval',\n",
    "### 'requester_user_flair',\n",
    "]\n",
    "\n",
    "get_flair = Pipeline([\n",
    "                     ('getFlair', StringExtractor('requester_user_flair')),\n",
    "                     ('counts', flairVect),\n",
    "                    ])\n",
    "\n",
    "get_subs = Pipeline([\n",
    "                     ('getSubs', SubredditExtractor('requester_subreddits_at_request')),\n",
    "                     ('counts', subVect),\n",
    "                    ])\n",
    "##feature union\n",
    "features = []\n",
    "features.append(('activity', ColumnExtractor(cols_act)))\n",
    "features.append(('reputation', ColumnExtractor(cols_rep) ))\n",
    "features.append(('flair', get_flair))\n",
    "features.append(('subs', get_subs))\n",
    "\n",
    "all_features = FeatureUnion(features)\n",
    "\n",
    "##scaling the features to make it stop executing bruh!\n",
    "source_scaler = StandardScaler(copy=False, with_mean=False, with_std=True)\n",
    "# source_scaler = MinMaxScaler()\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "#                      ('getText', TextExtractor('request_text_edit_aware')),\n",
    "                     ('all', all_features),\n",
    "                    ('scaler', source_scaler),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', LinearSVC(C=0.1)),\n",
    "#                     ('clf', MultinomialNB(alpha=0.1)),\n",
    "                    ('clf', linear_svc),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "print \"Fitting part 2!\"\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n",
    "# print \"NO!\"\n",
    "# probas = text_clf.predict_proba(X_test)\n",
    "# print \"YO!\"\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=0)\n",
    "print precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "#### roc_auc = roc_auc_score(y_test, predicted)\n",
    "roc_auc = roc_auc_score(y_test, probas[:,1])\n",
    "print \"ROC = \", roc_auc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test, predicted)\n",
    "#true negatives C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}\n",
    "tn = C[0][0]\n",
    "fn = C[1][0]\n",
    "tp = C[1][1]\n",
    "fp = C[0][1]\n",
    "##since labels are switched, invert the confusion matrix outputs: Pos = 0, Neg = 1\n",
    "#specificity = TN/TN+FP = tp/tp+fn\n",
    " \n",
    "print \"Specificity: \", float(tp)/(tp+fn)\n",
    "# print \"Precision: \", float(tn)/(tn+fn)\n",
    "# print \"Recall: \", float(tn)/(tn+fp)\n",
    "# print \"Accuracy: \", float(tn+tp)/(tn+tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test, predicted)\n",
    "#true negatives C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}\n",
    "tn = C[0][0]\n",
    "fn = C[1][0]\n",
    "tp = C[1][1]\n",
    "fp = C[0][1]\n",
    "##since labels are switched, invert the confusion matrix outputs: Pos = 0, Neg = 1\n",
    "#specificity = TN/TN+FP = tp/tp+fn\n",
    " \n",
    "print \"Specificity: \", float(tp)/(tp+fn)\n",
    "# print \"Precision: \", float(tn)/(tn+fn)\n",
    "# print \"Recall: \", float(tn)/(tn+fp)\n",
    "# print \"Accuracy: \", float(tn+tp)/(tn+tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8423"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flairVect.vocabulary_\n",
    "len(subVect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 3: Narratives\n",
      "Running in 4687.pts-33.flashmob03\n"
     ]
    }
   ],
   "source": [
    "print 'part 3: Narratives'\n",
    "print \"Running in 4687.pts-33.flashmob03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting part 3!\n",
      "0.797727272727 0.8125 0.80504587156 0.700176366843\n",
      "ROC =  0.572813786008\n",
      "Specificity:  0.340740740741\n"
     ]
    }
   ],
   "source": [
    "##vectorizer arguments blah!\n",
    "tokenizer=None#word_tokenize\n",
    "# stop_words=nltk.corpus.stopwords.words(\"english\")#None\n",
    "ngram_range=(1, 1)\n",
    "lowercase=True\n",
    "max_features=None\n",
    "binary=False\n",
    "dtype=np.float64\n",
    "\n",
    "desire_vocab = pd.read_csv('resources/narratives/desire.txt', names = [\"words\"])\n",
    "###create unigram vectorizer for desire features\n",
    "desireVect = CountVectorizer(\n",
    "                               vocabulary = desire_vocab.words,\n",
    "                               decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(1,1),\n",
    "                               lowercase=lowercase,\n",
    "#                                binary=binary,\n",
    "                               dtype=dtype,\n",
    "#                                max_features=max_features\n",
    "                            )\n",
    "\n",
    "family_vocab = pd.read_csv('resources/narratives/family.txt', names = [\"words\"])\n",
    "###create unigram vectorizer for family_vocab features\n",
    "familyVect = CountVectorizer(\n",
    "                               vocabulary = family_vocab.words,\n",
    "                               decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(1,1),\n",
    "                               lowercase=lowercase,\n",
    "#                                binary=binary,\n",
    "                               dtype=dtype,\n",
    "#                                max_features=max_features\n",
    "                            )\n",
    "\n",
    "job_vocab = pd.read_csv('resources/narratives/job.txt', names = [\"words\"])\n",
    "###create unigram vectorizer for job_vocab features\n",
    "jobVect = CountVectorizer(\n",
    "                               vocabulary = job_vocab.words,\n",
    "                               decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(1,1),\n",
    "                               lowercase=lowercase,\n",
    "#                                binary=binary,\n",
    "                               dtype=dtype,\n",
    "#                                max_features=max_features\n",
    "                            )\n",
    "\n",
    "money_vocab = pd.read_csv('resources/narratives/money.txt', names = [\"words\"])\n",
    "###create unigram vectorizer for money_vocab features\n",
    "###note that this list contains duplicate terms: bills, due\n",
    "moneyVect = CountVectorizer(\n",
    "                               vocabulary = money_vocab.words,\n",
    "                               decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(1,1),\n",
    "                               lowercase=lowercase,\n",
    "#                                binary=binary,\n",
    "                               dtype=dtype,\n",
    "#                                max_features=max_features\n",
    "                            )\n",
    "\n",
    "student_vocab = pd.read_csv('resources/narratives/student.txt', names = [\"words\"])\n",
    "###create unigram vectorizer for student features\n",
    "studentVect = CountVectorizer(\n",
    "                               vocabulary = student_vocab.words,\n",
    "                               decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(1,1),\n",
    "                               lowercase=lowercase,\n",
    "#                                binary=binary,\n",
    "                               dtype=dtype,\n",
    "#                                max_features=max_features\n",
    "                            )\n",
    "\n",
    "\n",
    "##feature union\n",
    "features = []\n",
    "features.append(('desire', desireVect))\n",
    "features.append(('family', familyVect))\n",
    "features.append(('job', jobVect))\n",
    "features.append(('money', moneyVect))\n",
    "features.append(('student', studentVect))\n",
    "all_features = FeatureUnion(features)\n",
    "\n",
    "##scaling the features to make it stop executing bruh!\n",
    "source_scaler = StandardScaler(copy=False, with_mean=False, with_std=True)\n",
    "# source_scaler = MinMaxScaler()\n",
    "# MinMaxScaler\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('getText', TextExtractor('request_text_edit_aware')),\n",
    "                     ('all', all_features),\n",
    "                     ('scaler', source_scaler),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultinomialNB(alpha=0.1)),\n",
    "#                     ('clf', linear_svc),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "print \"Fitting part 3!\"\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n",
    "# print \"NO!\"\n",
    "probas = text_clf.predict_proba(X_test)\n",
    "# print \"YO!\"\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=0)\n",
    "print precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# roc_auc = roc_auc_score(y_test, predicted)\n",
    "roc_auc = roc_auc_score(y_test, probas[:,1])\n",
    "print \"ROC = \", roc_auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test, predicted)\n",
    "#true negatives C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}\n",
    "tn = C[0][0]\n",
    "fn = C[1][0]\n",
    "tp = C[1][1]\n",
    "fp = C[0][1]\n",
    "##since labels are switched, invert the confusion matrix outputs: Pos = 0, Neg = 1\n",
    "#specificity = TN/TN+FP = tp/tp+fn\n",
    " \n",
    "print \"Specificity: \", float(tp)/(tp+fn)\n",
    "# print \"Precision: \", float(tn)/(tn+fn)\n",
    "# print \"Recall: \", float(tn)/(tn+fp)\n",
    "# print \"Accuracy: \", float(tn+tp)/(tn+tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 4: Moral foundations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"part 4: Moral foundations\"\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Moral Foundations dict\n"
     ]
    }
   ],
   "source": [
    "###parse the dictionary bro\n",
    "with open('resources/MoralFoundations.dic', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "count = 0\n",
    "l = 0\n",
    "\n",
    "##tokenizer to get the number of words in the sentence\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "##\n",
    "# list = [][]\n",
    "list_1 = []\n",
    "list_2 = []\n",
    "list_3 = []\n",
    "list_4 = []\n",
    "list_5 = []\n",
    "list_6 = []\n",
    "list_7 = []\n",
    "list_8 = []\n",
    "list_9 = []\n",
    "list_10 = []\n",
    "list_11 = []\n",
    "\n",
    "print \"Parsing Moral Foundations dict\"\n",
    "for line in lines:\n",
    "    if \"%\" in line:\n",
    "        count +=1 \n",
    "#         print line\n",
    "        continue\n",
    "    if count < 2:\n",
    "        continue\n",
    "    first = 0\n",
    "    for word in tokenizer.tokenize(line):\n",
    "#         print word\n",
    "        if first == 0:\n",
    "            if \"*\" in line:\n",
    "                word = word + \".*\"\n",
    "            term = word\n",
    "#             print \"Word: \", term\n",
    "        \n",
    "        if first > 0:\n",
    "            label = int(word)\n",
    "#             print \"Label: \", label\n",
    "            if label == 1:\n",
    "                list_1.append(term)\n",
    "            elif label == 2:\n",
    "                list_2.append(term)\n",
    "            elif label == 3:\n",
    "                list_3.append(term)\n",
    "            elif label == 4:\n",
    "                list_4.append(term)\n",
    "            elif label == 5:\n",
    "                list_5.append(term)\n",
    "            elif label == 6:\n",
    "                list_6.append(term)\n",
    "            elif label == 7:\n",
    "                list_7.append(term)\n",
    "            elif label == 8:\n",
    "                list_8.append(term)\n",
    "            elif label == 9:\n",
    "                list_9.append(term)\n",
    "            elif label == 10:\n",
    "                list_10.append(term)\n",
    "            elif label == 11:\n",
    "                list_11.append(term)\n",
    "        first += 1\n",
    "#     print \"---\"\n",
    "    l+= 1\n",
    "# print \"Lines done = \", l\n",
    "moral_foundations = []\n",
    "moral_foundations.append(list_1)\n",
    "moral_foundations.append(list_2)\n",
    "moral_foundations.append(list_3)\n",
    "moral_foundations.append(list_4)\n",
    "moral_foundations.append(list_5)\n",
    "moral_foundations.append(list_6)\n",
    "moral_foundations.append(list_7)\n",
    "moral_foundations.append(list_8)\n",
    "moral_foundations.append(list_9)\n",
    "moral_foundations.append(list_10)\n",
    "moral_foundations.append(list_11)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# moral_foundations[10]\n",
    "# postbanhate_iter += np.sum(arr)\n",
    "# for text in df1.body:\n",
    "#     prebanWords_iter += len(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting part 3!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need more than 0 values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-4ea329e42079>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;31m###fit training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Fitting part 3!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m \u001b[0mtext_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;31m### predict on test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \"\"\"\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_pre_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    497\u001b[0m             for name, trans in self.transformer_list)\n\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[0mXs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_transformer_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: need more than 0 values to unpack"
     ]
    }
   ],
   "source": [
    "# ptrn = r\"\\b(\"+ \"|\".join(moral_foundations[0]) + r\")\\b\"\n",
    "import functools\n",
    "from functools import partial\n",
    "\n",
    "##tokenizer to get the number of words in the sentence\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def apply_func(func, X, *args, **kwargs):\n",
    "    '''\n",
    "    Apply a function that applies to a single row to an entire matrix \n",
    "    \n",
    "    :param func: the function\n",
    "    :param X: the matrix\n",
    "    \n",
    "    :returns: a new matrix, where each row is the func applied to the rows of X\n",
    "    '''\n",
    "    func_ = partial(func, *args, **kwargs)\n",
    "    X_ = np.array([func_(i) for i in X])\n",
    "    return X_.reshape((len(X), np.prod(X_.shape)/len(X)))\n",
    "\n",
    "\n",
    "def get_scores(text, mf_label):\n",
    "    ###count number of words in the sentence\n",
    "    RE = re.compile('[0-9a-z-]', re.I)\n",
    "    words = filter(lambda w: RE.search(w) and w.replace('-', ''), tokenizer.tokenize(text))\n",
    "    wordc = max(1, len(words))\n",
    "    print wordc\n",
    "    \n",
    "    ###count number of matches with MF dict entries\n",
    "    ptrn = r\"\\b(\"+ \"|\".join(moral_foundations[mf_label]) + r\")\\b\"\n",
    "    str_ = \"safer safe safest something!\"\n",
    "    reg = re.compile(ptrn)\n",
    "    score = 0\n",
    "    for word in tokenizer.tokenize(str_):\n",
    "        score += len(reg.findall(word))\n",
    "\n",
    "    return float(score)/wordc\n",
    "\n",
    "class TextExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.vars]  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "\n",
    "class FunctionTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, the_function):\n",
    "        '''\n",
    "        Wrap a function into the transform method of a transformer.\n",
    "        \n",
    "        Use: \n",
    "            def plus_one(X):\n",
    "                return X+1\n",
    "            \n",
    "            f = FunctionTransformer(plus_one)\n",
    "            f.fit_transform(np.array([[1, 2, 3]]), [0, 0, 1])\n",
    "            Out[21]: array([[2, 3, 4]])        \n",
    "            \n",
    "        :param the_function: function that takes the matrix X as the first argument, \n",
    "            and outputs the desired transformed X \n",
    "        '''\n",
    "        self.the_function = the_function\n",
    "    def fit(self, *args, **kwargs):#does nothing at all\n",
    "        return self\n",
    "    def transform(self, X, **transform_params):\n",
    "        return self.the_function(X)\n",
    "\n",
    "\n",
    "\n",
    "##feature union\n",
    "features = []\n",
    "\n",
    "# for i in range(0,11):\n",
    "#     print i\n",
    "getMFTransformer = FunctionTransformer(partial(apply_func, get_scores, mf_label=0))\n",
    "#     features.append(('mf'+i.astype(str), FunctionTransformer(partial(apply_func, get_scores, mf_label=i))))\n",
    "all_features = FeatureUnion(features)\n",
    "# print len(all_features)\n",
    "##scaling the features to make it stop executing bruh!\n",
    "source_scaler = StandardScaler(copy=False, with_mean=False, with_std=True)\n",
    "# source_scaler = MinMaxScaler()\n",
    "# MinMaxScaler\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('getText', TextExtractor('request_text_edit_aware')),\n",
    "                     ('all', all_features),\n",
    "                     ('scaler', source_scaler),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', MultinomialNB(alpha=0.1)),\n",
    "                    ('clf', linear_svc),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "print \"Fitting part 3!\"\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n",
    "# print \"NO!\"\n",
    "probas = text_clf.predict_proba(X_test)\n",
    "# print \"YO!\"\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=0)\n",
    "print precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# roc_auc = roc_auc_score(y_test, predicted)\n",
    "roc_auc = roc_auc_score(y_test, probas[:,1])\n",
    "print \"ROC = \", roc_auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test, predicted)\n",
    "#true negatives C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}\n",
    "tn = C[0][0]\n",
    "fn = C[1][0]\n",
    "tp = C[1][1]\n",
    "fp = C[0][1]\n",
    "##since labels are switched, invert the confusion matrix outputs: Pos = 0, Neg = 1\n",
    "#specificity = TN/TN+FP = tp/tp+fn\n",
    " \n",
    "print \"Specificity: \", float(tp)/(tp+fn)\n",
    "# print \"Precision: \", float(tn)/(tn+fn)\n",
    "# print \"Recall: \", float(tn)/(tn+fp)\n",
    "# print \"Accuracy: \", float(tn+tp)/(tn+tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "ptrn = r\"\\b(\"+ \"|\".join(moral_foundations[10]) + r\")\\b\"\n",
    "str_ = \"safelexs ethical safe safest something!\"\n",
    "\n",
    "reg = re.compile(ptrn)\n",
    "score = 0\n",
    "\n",
    "for word in tokenizer.tokenize(str_):\n",
    "    score += len(reg.findall(word))\n",
    "\n",
    "print score\n",
    "#     print len(reg.match(str_).group())\n",
    "# if re.compile(ptrn).match(str_).group() == None:\n",
    "#     print \"No match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCounts(text):\n",
    "    string = \"\"\n",
    "    ptrn = r\"\\b(\"+ \"|\".join(moral_foundations[0]) + r\")\\b\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'to_String'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-40e7d1e827fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_String\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'to_String'"
     ]
    }
   ],
   "source": [
    "i.to_String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "25\n",
      "69\n",
      "33\n",
      "72\n",
      "45\n",
      "229\n",
      "126\n",
      "1\n",
      " \n",
      "112\n",
      "81\n",
      "27\n",
      "36\n",
      "156\n",
      "1\n",
      "\n",
      "2\n",
      "edit: my*\n",
      "68\n",
      "7\n",
      "Biochemistry is a hell of a major. \n",
      "47\n",
      "185\n",
      "66\n",
      "59\n",
      "81\n",
      "46\n",
      "44\n",
      "17\n",
      "138\n",
      "58\n",
      "147\n",
      "45\n",
      "55\n",
      "35\n",
      "117\n",
      "66\n",
      "58\n",
      "61\n",
      "1\n",
      "\n",
      "177\n",
      "52\n",
      "130\n",
      "34\n",
      "38\n",
      "82\n",
      "101\n",
      "23\n",
      "1\n",
      "\n",
      "89\n",
      "15\n",
      "4\n",
      "What a sad time.\n",
      "70\n",
      "7\n",
      "AHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH!!!!!!!!!\n",
      "\n",
      "[VA area, serious offers only please]\n",
      "103\n",
      "73\n",
      "44\n",
      "118\n",
      "82\n",
      "72\n",
      "57\n",
      "59\n",
      "46\n",
      "66\n",
      "57\n",
      "16\n",
      "57\n",
      "83\n",
      "69\n",
      "11\n",
      "39\n",
      "46\n",
      "74\n",
      "19\n",
      "122\n",
      "23\n",
      "24\n",
      "12\n",
      "116\n",
      "113\n",
      "101\n",
      "131\n",
      "42\n",
      "95\n",
      "86\n",
      "179\n",
      "56\n",
      "1\n",
      "\n",
      "101\n",
      "9\n",
      "*just to be clear: by CA, I mean California\n",
      "41\n",
      "30\n",
      "12\n",
      "54\n",
      "112\n",
      "57\n",
      "63\n",
      "63\n",
      "48\n",
      "96\n",
      "59\n",
      "37\n",
      "44\n",
      "32\n",
      "25\n",
      "73\n",
      "158\n",
      "39\n",
      "55\n",
      "98\n",
      "137\n",
      "117\n",
      "21\n",
      "127\n",
      "53\n",
      "13\n",
      "109\n",
      "114\n",
      "43\n",
      "160\n",
      "33\n",
      "55\n",
      "97\n",
      "1\n",
      "\n",
      "35\n",
      "203\n",
      "23\n",
      "8\n",
      "Plus, I've never met any local redditors.\n",
      "72\n",
      "125\n",
      "113\n",
      "63\n",
      "31\n",
      "85\n",
      "66\n",
      "1\n",
      "\n",
      "43\n",
      "95\n",
      "35\n",
      "42\n",
      "1\n",
      "\n",
      "64\n",
      "12\n",
      "68\n",
      "85\n",
      "63\n",
      "39\n",
      "121\n",
      "102\n",
      "54\n",
      "1\n",
      "Fail\n",
      "76\n",
      "68\n",
      "34\n",
      "23\n",
      "63\n",
      "69\n",
      "78\n",
      "49\n",
      "108\n",
      "296\n",
      "83\n",
      "50\n",
      "27\n",
      "58\n",
      "130\n",
      "132\n",
      "31\n",
      "62\n",
      "58\n",
      "60\n",
      "95\n",
      "21\n",
      "18\n",
      "224\n",
      "26\n",
      "38\n",
      "50\n",
      "5\n",
      "Thank you for your consideration. :)\n",
      "172\n",
      "35\n",
      "100\n",
      "84\n",
      "133\n",
      "76\n",
      "102\n",
      "99\n",
      "31\n",
      "79\n",
      "147\n",
      "77\n",
      "103\n",
      "90\n",
      "87\n",
      "5\n",
      "It would be much appreciated.\n",
      "58\n",
      "40\n",
      "16\n",
      "127\n",
      "32\n",
      "40\n",
      "177\n",
      "57\n",
      "27\n",
      "34\n",
      "45\n",
      "118\n",
      "71\n",
      "60\n",
      "59\n",
      "62\n",
      "28\n",
      "137\n",
      "44\n",
      "29\n",
      "47\n",
      "86\n",
      "24\n",
      "68\n",
      "7\n",
      "No sob story just hungry and bored.\n",
      "1\n",
      "\n",
      "43\n",
      "85\n",
      "69\n",
      "98\n",
      "12\n",
      "95\n",
      "6\n",
      "I'm sooooo hungry\n",
      "\n",
      "im black\n",
      "57\n",
      "206\n",
      "48\n",
      "176\n",
      "95\n",
      "23\n",
      "48\n",
      "176\n",
      "86\n",
      "54\n",
      "24\n",
      "327\n",
      "43\n",
      "33\n",
      "74\n",
      "131\n",
      "184\n",
      "123\n",
      "29\n",
      "40\n",
      "129\n",
      "62\n",
      "45\n",
      "210\n",
      "28\n",
      "98\n",
      "96\n",
      "111\n",
      "135\n",
      "2\n",
      "**edit:** nevermind.\n",
      "95\n",
      "48\n",
      "17\n",
      "62\n",
      "19\n",
      "112\n",
      "1\n",
      "\n",
      "53\n",
      "53\n",
      "84\n",
      "13\n",
      "39\n",
      "12\n",
      "110\n",
      "113\n",
      "168\n",
      "67\n",
      "104\n",
      "44\n",
      "104\n",
      "116\n",
      "1\n",
      "\n",
      "67\n",
      "170\n",
      "92\n",
      "75\n",
      "17\n",
      "38\n",
      "32\n",
      "82\n",
      "14\n",
      "116\n",
      "33\n",
      "60\n",
      "131\n",
      "49\n",
      "76\n",
      "3\n",
      "Anyone please? California.\n",
      "150\n",
      "109\n",
      "99\n",
      "43\n",
      "1\n",
      "\n",
      "11\n",
      "23\n",
      "52\n",
      "42\n",
      "16\n",
      "57\n",
      "19\n",
      "70\n",
      "94\n",
      "215\n",
      "1\n",
      "\n",
      "34\n",
      "26\n",
      "49\n",
      "79\n",
      "118\n",
      "64\n",
      "37\n",
      "97\n",
      "81\n",
      "45\n",
      "108\n",
      "100\n",
      "20\n",
      "289\n",
      "38\n",
      "800\n",
      "36\n",
      "34\n",
      "9\n",
      "Simple as that. Just chilling. Pizza would be cool.\n",
      "63\n",
      "87\n",
      "1\n",
      "\n",
      "220\n",
      "1\n",
      "\n",
      "31\n",
      "64\n",
      "31\n",
      "12\n",
      "37\n",
      "95\n",
      "49\n",
      "162\n",
      "49\n",
      "32\n",
      "1\n",
      "\n",
      "100\n",
      "5\n",
      "Really really hungry and broke.\n",
      "70\n",
      "247\n",
      "48\n",
      "30\n",
      "62\n",
      "31\n",
      "123\n",
      "104\n",
      "51\n",
      "28\n",
      "29\n",
      "30\n",
      "36\n",
      "138\n",
      "176\n",
      "1\n",
      "\n",
      "68\n",
      "120\n",
      "18\n",
      "144\n",
      "154\n",
      "23\n",
      "30\n",
      "330\n",
      "102\n",
      "34\n",
      "87\n",
      "78\n",
      "37\n",
      "105\n",
      "41\n",
      "67\n",
      "37\n",
      "52\n",
      "127\n",
      "66\n",
      "70\n",
      "65\n",
      "47\n",
      "32\n",
      "34\n",
      "1\n",
      "\n",
      "137\n",
      "32\n",
      "120\n",
      "89\n",
      "141\n",
      "32\n",
      "44\n",
      "51\n",
      "102\n",
      "114\n",
      "48\n",
      "76\n",
      "59\n",
      "46\n",
      "70\n",
      "56\n",
      "236\n",
      "56\n",
      "117\n",
      "26\n",
      "35\n",
      "34\n",
      "82\n",
      "129\n",
      "124\n",
      "67\n",
      "83\n",
      "277\n",
      "72\n",
      "73\n",
      "71\n",
      "30\n",
      "31\n",
      "3\n",
      "Pretty pretty please?\n",
      "35\n",
      "96\n",
      "117\n",
      "37\n",
      "109\n",
      "316\n",
      "85\n",
      "112\n",
      "70\n",
      "48\n",
      "17\n",
      "93\n",
      "143\n",
      "248\n",
      "46\n",
      "40\n",
      "5\n",
      "Any pizza's good pizza ;)\n",
      "37\n",
      "44\n",
      "41\n",
      "207\n",
      "4\n",
      "Anything in Madison, WI\n",
      "42\n",
      "137\n",
      "11\n",
      "105\n",
      "80\n",
      "74\n",
      "17\n",
      "35\n",
      "55\n",
      "708\n",
      "49\n",
      "44\n",
      "98\n",
      "63\n",
      "100\n",
      "48\n",
      "197\n",
      "1\n",
      "*\n",
      "46\n",
      "61\n",
      "103\n",
      "51\n",
      "34\n",
      "10\n",
      "It would be much appreciated, and payed forward later on. \n",
      "167\n",
      "140\n",
      "29\n",
      "51\n",
      "87\n",
      "34\n",
      "59\n",
      "28\n",
      "121\n",
      "64\n",
      "133\n",
      "51\n",
      "30\n",
      "50\n",
      "36\n",
      "188\n",
      "34\n",
      "88\n",
      "111\n",
      "149\n",
      "34\n",
      "138\n",
      "48\n",
      "181\n",
      "62\n",
      "45\n",
      "38\n",
      "28\n",
      "59\n",
      "33\n",
      "93\n",
      "121\n",
      "28\n",
      "14\n",
      "70\n",
      "153\n",
      "1\n",
      "\n",
      "16\n",
      "145\n",
      "83\n",
      "81\n",
      "40\n",
      "14\n",
      "45\n",
      "29\n",
      "292\n",
      "82\n",
      "347\n",
      "34\n",
      "71\n",
      "62\n",
      "45\n",
      "19\n",
      "57\n",
      "58\n",
      "19\n",
      "45\n",
      "159\n",
      "1\n",
      "\n",
      "34\n",
      "81\n",
      "43\n",
      "43\n",
      "18\n",
      "144\n",
      "29\n",
      "187\n",
      "115\n",
      "26\n",
      "150\n",
      "35\n",
      "41\n",
      "12\n",
      "12\n",
      "79\n",
      "46\n",
      "83\n",
      "110\n",
      "27\n",
      "44\n",
      "75\n",
      "67\n",
      "115\n",
      "7\n",
      "a pizza would brighten my childrens thanksgiving \n",
      "63\n",
      "136\n",
      "38\n",
      "21\n",
      "34\n",
      "107\n",
      "69\n",
      "227\n",
      "136\n",
      "65\n",
      "117\n",
      "50\n",
      "63\n",
      "65\n",
      "50\n",
      "8\n",
      "You would make me a very happy person.\n",
      "60\n",
      "92\n",
      "48\n",
      "19\n",
      "46\n",
      "39\n",
      "45\n",
      "54\n",
      "95\n",
      "32\n",
      "46\n",
      "58\n",
      "35\n",
      "24\n",
      "15\n",
      "102\n",
      "34\n",
      "96\n",
      "67\n",
      "35\n",
      "18\n",
      "95\n",
      "100\n",
      "87\n",
      "52\n",
      "52\n",
      "190\n",
      "191\n",
      "88\n",
      "92\n",
      "160\n",
      "51\n",
      "274\n",
      "14\n",
      "41\n",
      "185\n",
      "43\n",
      "46\n",
      "12\n",
      "92\n",
      "169\n",
      "83\n",
      "5\n",
      "Hope I get a response!\n",
      "62\n",
      "16\n",
      "135\n",
      "156\n",
      "1\n",
      "\n",
      "68\n",
      "59\n",
      "73\n",
      "59\n",
      "127\n",
      "137\n",
      "180\n",
      "54\n",
      "23\n",
      "61\n",
      "12\n",
      "208\n",
      "104\n",
      "33\n",
      "21\n",
      "47\n",
      "48\n",
      "28\n",
      "82\n",
      "165\n",
      "14\n",
      "112\n",
      "19\n",
      "40\n",
      "64\n",
      "111\n",
      "17\n",
      "247\n",
      "15\n",
      "6\n",
      "I do have verification code btw!\n",
      "1\n",
      "\n",
      "27\n",
      "31\n",
      "59\n",
      "1\n",
      "\n",
      "31\n",
      "17\n",
      "77\n",
      "134\n",
      "47\n",
      "62\n",
      "80\n",
      "101\n",
      "51\n",
      "183\n",
      "26\n",
      "30\n",
      "40\n",
      "226\n",
      "131\n",
      "114\n",
      "101\n",
      "42\n",
      "66\n",
      "25\n",
      "48\n",
      "67\n",
      "50\n",
      "59\n",
      "19\n",
      "152\n",
      "109\n",
      "36\n",
      "40\n",
      "83\n",
      "109\n",
      "27\n",
      "97\n",
      "6\n",
      "Just a pizza or two please ^_^\n",
      "96\n",
      "133\n",
      "313\n",
      "63\n",
      "128\n",
      "100\n",
      "25\n",
      "92\n",
      "113\n",
      "167\n",
      "23\n",
      "12\n",
      "26\n",
      "36\n",
      "41\n",
      "20\n",
      "92\n",
      "214\n",
      "48\n",
      "81\n",
      "123\n",
      "58\n",
      "90\n",
      "49\n",
      "104\n",
      "28\n",
      "48\n",
      "61\n",
      "115\n",
      "89\n",
      "94\n",
      "73\n",
      "79\n",
      "22\n",
      "66\n",
      "196\n",
      "160\n",
      "35\n",
      "145\n",
      "78\n",
      "104\n",
      "140\n",
      "39\n",
      "54\n",
      "99\n",
      "223\n",
      "10\n",
      "It sure would make my day to get a pie. \n",
      "34\n",
      "170\n",
      "4\n",
      "Blasting music and hungry :(\n",
      "57\n",
      "81\n",
      "44\n",
      "75\n",
      "36\n",
      "25\n",
      "1\n",
      "\n",
      "72\n",
      "21\n",
      "63\n",
      "27\n",
      "84\n",
      "1\n",
      "\n",
      "17\n",
      "39\n",
      "106\n",
      "90\n",
      "136\n",
      "108\n",
      "86\n",
      "178\n",
      "18\n",
      "61\n",
      "61\n",
      "692\n",
      "29\n",
      "1\n",
      "\n",
      "22\n",
      "88\n",
      "49\n",
      "4\n",
      "Please and thank you!\n",
      "84\n",
      "69\n",
      "132\n",
      "56\n",
      "103\n",
      "152\n",
      "45\n",
      "1\n",
      "\n",
      "363\n",
      "4\n",
      "LetsFytingLove is the best!\n",
      "37\n",
      "60\n",
      "77\n",
      "29\n",
      "116\n",
      "84\n",
      "36\n",
      "127\n",
      "45\n",
      "113\n",
      "55\n",
      "30\n",
      "39\n",
      "163\n",
      "37\n",
      "173\n",
      "25\n",
      "87\n",
      "41\n",
      "35\n",
      "48\n",
      "26\n",
      "94\n",
      "148\n",
      "67\n",
      "73\n",
      "54\n",
      "40\n",
      "92\n",
      "126\n",
      "27\n",
      "97\n",
      "158\n",
      "142\n",
      "11\n",
      "45\n",
      "27\n",
      "9\n",
      "Alternatively, will write limerick for pizza.\n",
      "\n",
      "I appreciate it.\n",
      "107\n",
      "108\n",
      "37\n",
      "86\n",
      "24\n",
      "163\n",
      "87\n",
      "86\n",
      "19\n",
      "131\n",
      "119\n",
      "17\n",
      "1\n",
      "\n",
      "40\n",
      "40\n",
      "180\n",
      "97\n",
      "39\n",
      "89\n",
      "51\n",
      "100\n",
      "117\n",
      "78\n",
      "150\n",
      "117\n",
      "120\n",
      "163\n",
      "280\n",
      "57\n",
      "278\n",
      "51\n",
      "69\n",
      "94\n",
      "15\n",
      "25\n",
      "33\n",
      "22\n",
      "19\n",
      "111\n",
      "174\n",
      "14\n",
      "61\n",
      "126\n",
      "91\n",
      "90\n",
      "5\n",
      "No money until next friday : (\n",
      "111\n",
      "171\n",
      "66\n",
      "49\n",
      "24\n",
      "7\n",
      "I will answer any questions you have.\n",
      "15\n",
      "198\n",
      "62\n",
      "65\n",
      "89\n",
      "115\n",
      "28\n",
      "232\n",
      "43\n",
      "56\n",
      "1\n",
      "\n",
      "64\n",
      "11\n",
      "485\n",
      "41\n",
      "28\n",
      "55\n",
      "31\n",
      "54\n",
      "33\n",
      "38\n",
      "83\n",
      "76\n",
      "29\n",
      "38\n",
      "11\n",
      "43\n",
      "123\n",
      "27\n",
      "64\n",
      "50\n",
      "38\n",
      "73\n",
      "35\n",
      "42\n",
      "129\n",
      "32\n",
      "24\n",
      "156\n",
      "38\n",
      "116\n",
      "142\n",
      "38\n",
      "180\n",
      "99\n",
      "116\n",
      "139\n",
      "214\n",
      "78\n",
      "50\n",
      "20\n",
      "42\n",
      "55\n",
      "184\n",
      "22\n",
      "79\n",
      "19\n",
      "16\n",
      "34\n",
      "1\n",
      "\n",
      "67\n",
      "93\n",
      "17\n",
      "95\n",
      "34\n",
      "44\n",
      "120\n",
      "100\n",
      "190\n",
      "156\n",
      "50\n",
      "129\n",
      "279\n",
      "19\n",
      "47\n",
      "23\n",
      "83\n",
      "183\n",
      "79\n",
      "70\n",
      "158\n",
      "389\n",
      "130\n",
      "18\n",
      "69\n",
      "78\n",
      "152\n",
      "79\n",
      "48\n",
      "144\n",
      "7\n",
      "I like pizza, you like pizza. PIZZA?\n",
      "\n",
      "21\n",
      "44\n",
      "137\n",
      "55\n",
      "270\n",
      "96\n",
      "2\n",
      "Thanks yall!\n",
      "79\n",
      "62\n",
      "172\n",
      "49\n",
      "93\n",
      "58\n",
      "40\n",
      "67\n",
      "39\n",
      "38\n",
      "16\n",
      "61\n",
      "22\n",
      "63\n",
      "81\n",
      "9\n",
      "http://www.reddit.com/r/self/comments/ihc7v/found_a_dudes_iphone_4_in_boston_last_night/\n",
      "39\n",
      "39\n",
      "102\n",
      "18\n",
      "31\n",
      "256\n",
      "254\n",
      "56\n",
      "166\n",
      "84\n",
      "116\n",
      "142\n",
      "17\n",
      "62\n",
      "48\n",
      "167\n",
      "139\n",
      "27\n",
      "48\n",
      "70\n",
      "15\n",
      "372\n",
      "97\n",
      "40\n",
      "92\n",
      "46\n",
      "14\n",
      "51\n",
      "119\n",
      "61\n",
      "65\n",
      "109\n",
      "51\n",
      "174\n",
      "147\n",
      "148\n",
      "36\n",
      "50\n",
      "21\n",
      "61\n",
      "98\n",
      "24\n",
      "149\n",
      "43\n",
      "82\n",
      "62\n",
      "99\n",
      "82\n",
      "44\n",
      "72\n",
      "89\n",
      "35\n",
      "2\n",
      "Bozeman, MT\n",
      "93\n",
      "145\n",
      "18\n",
      "39\n",
      "130\n",
      "10\n",
      "Thanks in advance to anybody willing to help us out.\n",
      "64\n",
      "52\n",
      "313\n",
      "88\n",
      "70\n",
      "12\n",
      "44\n",
      "72\n",
      "13\n",
      "57\n",
      "20\n",
      "19\n",
      "86\n",
      "105\n",
      "32\n",
      "17\n",
      "34\n",
      "28\n",
      "28\n",
      "48\n",
      "181\n",
      "146\n",
      "106\n",
      "26\n",
      "105\n",
      "95\n",
      "51\n",
      "170\n",
      "34\n",
      "58\n",
      "51\n",
      "30\n",
      "52\n",
      "75\n",
      "29\n",
      "146\n",
      "33\n",
      "5\n",
      "I would love a pizza!\n",
      "7\n",
      "OP WILL deliver with pics va PM. \n",
      "174\n",
      "99\n",
      "57\n",
      "41\n",
      "84\n",
      "40\n",
      "103\n",
      "78\n",
      "36\n",
      "36\n",
      "1\n",
      "\n",
      "345\n",
      "85\n",
      "45\n",
      "60\n",
      "95\n",
      "58\n",
      "159\n",
      "73\n",
      "1\n",
      "\n",
      "71\n",
      "34\n",
      "53\n",
      "152\n",
      "17\n",
      "1\n",
      "\n",
      "79\n",
      "36\n",
      "85\n",
      "39\n",
      "131\n",
      "33\n",
      "228\n",
      "166\n",
      "404\n",
      "84\n",
      "289\n",
      "148\n",
      "142\n",
      "191\n",
      "45\n",
      "27\n",
      "109\n",
      "56\n",
      "115\n",
      "57\n",
      "187\n",
      "15\n",
      "5\n",
      "This sub reddit is awesome\n",
      "45\n",
      "79\n",
      "263\n",
      "36\n",
      "57\n",
      "120\n",
      "67\n",
      "45\n",
      "45\n",
      "106\n",
      "24\n",
      "97\n",
      "37\n",
      "147\n",
      "31\n",
      "11\n",
      "327\n",
      "43\n",
      "47\n",
      "9\n",
      "Caught her sleeping with boss.  Springfield Missouri area.  Thanks.\n",
      "72\n",
      "111\n",
      "88\n",
      "58\n",
      "27\n",
      "99\n",
      "238\n",
      "38\n",
      "41\n",
      "86\n",
      "27\n",
      "7\n",
      "The things we do for our pets...\n",
      "28\n",
      "188\n",
      "29\n",
      "44\n",
      "267\n",
      "7\n",
      "Graduating on April 28th, I love pizza.\n",
      "293\n",
      "81\n",
      "64\n",
      "76\n",
      "63\n",
      "57\n",
      "38\n",
      "9\n",
      "Studying for physiology and anatomy -_- fuck my life.. honolulu\n",
      "25\n",
      "53\n",
      "70\n",
      "57\n",
      "29\n",
      "36\n",
      "86\n",
      "62\n",
      "38\n",
      "30\n",
      "119\n",
      "79\n",
      "13\n",
      "7\n",
      "Now all I want is Pizza Hut. :)\n",
      "57\n",
      "23\n",
      "25\n",
      "113\n",
      "68\n",
      "38\n",
      "1\n",
      "\n",
      "42\n",
      "17\n",
      "40\n",
      "88\n",
      "43\n",
      "21\n",
      "143\n",
      "13\n",
      "31\n",
      "93\n",
      "66\n",
      "149\n",
      "65\n",
      "92\n",
      "27\n",
      "54\n",
      "142\n",
      "58\n",
      "82\n",
      "311\n",
      "95\n",
      "80\n",
      "53\n",
      "125\n",
      "61\n",
      "69\n",
      "35\n",
      "49\n",
      "328\n",
      "449\n",
      "61\n",
      "55\n",
      "213\n",
      "38\n",
      "120\n",
      "74\n",
      "28\n",
      "58\n",
      "201\n",
      "1\n",
      "\n",
      "39\n",
      "105\n",
      "29\n",
      "15\n",
      "73\n",
      "16\n",
      "4\n",
      "Please and thank you. :)\n",
      "449\n",
      "134\n",
      "20\n",
      "133\n",
      "141\n",
      "146\n",
      "97\n",
      "57\n",
      "26\n",
      "65\n",
      "59\n",
      "197\n",
      "20\n",
      "234\n",
      "60\n",
      "57\n",
      "48\n",
      "398\n",
      "45\n",
      "47\n",
      "21\n",
      "58\n",
      "27\n",
      "21\n",
      "115\n",
      "88\n",
      "222\n",
      "46\n",
      "36\n",
      "83\n",
      "26\n",
      "125\n",
      "203\n",
      "85\n",
      "89\n",
      "92\n",
      "12\n",
      "86\n",
      "52\n",
      "68\n",
      "72\n",
      "18\n",
      "49\n",
      "66\n",
      "51\n",
      "56\n",
      "315\n",
      "27\n",
      "44\n",
      "51\n",
      "8\n",
      "I would buy one myself if I could.\n",
      "95\n",
      "127\n",
      "142\n",
      "29\n",
      "29\n",
      "103\n",
      "138\n",
      "79\n",
      "59\n",
      "22\n",
      "120\n",
      "233\n",
      "44\n",
      "283\n",
      "22\n",
      "33\n",
      "51\n",
      "26\n",
      "88\n",
      "45\n",
      "11\n",
      "104\n",
      "18\n",
      "129\n",
      "26\n",
      "99\n",
      "63\n",
      "58\n",
      "23\n",
      "6\n",
      "I got pizza'd, thanks Lexically. \n",
      "54\n",
      "35\n",
      "123\n",
      "44\n",
      "45\n",
      "47\n",
      "238\n",
      "50\n",
      "37\n",
      "103\n",
      "81\n",
      "45\n",
      "58\n",
      "51\n",
      "130\n",
      "85\n",
      "45\n",
      "100\n",
      "131\n",
      "24\n",
      "39\n",
      "113\n",
      "65\n",
      "75\n",
      "141\n",
      "18\n",
      "52\n",
      "155\n",
      "1\n",
      "\n",
      "45\n",
      "45\n",
      "85\n",
      "42\n",
      "52\n",
      "112\n",
      "68\n",
      "24\n",
      "82\n",
      "23\n",
      "27\n",
      "82\n",
      "95\n",
      "45\n",
      "137\n",
      "142\n",
      "56\n",
      "78\n",
      "107\n",
      "96\n",
      "52\n",
      "66\n",
      "35\n",
      "85\n",
      "84\n",
      "95\n",
      "393\n",
      "25\n",
      "39\n",
      "40\n",
      "69\n",
      "75\n",
      "59\n",
      "172\n",
      "43\n",
      "87\n",
      "39\n",
      "139\n",
      "15\n",
      "62\n",
      "301\n",
      "78\n",
      "10\n",
      "Pregnant and craving pizza!! Will pay it forward on payday! :)\n",
      "68\n",
      "198\n",
      "12\n",
      "42\n",
      "231\n",
      "119\n",
      "28\n",
      "42\n",
      "51\n",
      "137\n",
      "101\n",
      "99\n",
      "40\n",
      "102\n",
      "70\n",
      "41\n",
      "29\n",
      "142\n",
      "38\n",
      "11\n",
      "41\n",
      "28\n",
      "7\n",
      "Poor college kids who want to eat:(\n",
      "144\n",
      "86\n",
      "193\n",
      "135\n",
      "90\n",
      "115\n",
      "21\n",
      "73\n",
      "44\n",
      "23\n",
      "88\n",
      "45\n",
      "199\n",
      "104\n",
      "53\n",
      "84\n",
      "33\n",
      "97\n",
      "30\n",
      "1\n",
      "\n",
      "55\n",
      "112\n",
      "12\n",
      "65\n",
      "146\n",
      "24\n",
      "47\n",
      "24\n",
      "80\n",
      "1\n",
      "\n",
      "30\n",
      "158\n",
      "123\n",
      "54\n",
      "145\n",
      "80\n",
      "71\n",
      "52\n",
      "32\n",
      "62\n",
      "89\n",
      "123\n",
      "169\n",
      "33\n",
      "852\n",
      "57\n",
      "227\n",
      "189\n",
      "152\n",
      "56\n",
      "119\n",
      "46\n",
      "63\n",
      "49\n",
      "46\n",
      "140\n",
      "49\n",
      "1\n",
      "\n",
      "46\n",
      "260\n",
      "201\n",
      "342\n",
      "52\n",
      "19\n",
      "70\n",
      "171\n",
      "100\n",
      "142\n",
      "75\n",
      "34\n",
      "55\n",
      "49\n",
      "39\n",
      "39\n",
      "97\n",
      "49\n",
      "10\n",
      "EDIT: Before pics are [here](http://imgur.com/a/DHvJ4).\n",
      "3\n",
      "Amherst Ohio here\n",
      "49\n",
      "111\n",
      "156\n",
      "26\n",
      "31\n",
      "21\n",
      "153\n",
      "1\n",
      "\n",
      "22\n",
      "41\n",
      "88\n",
      "37\n",
      "136\n",
      "74\n",
      "269\n",
      "74\n",
      "470\n",
      "34\n",
      "96\n",
      "14\n",
      "35\n",
      "7\n",
      "Could use a pepperroni and mushroom visitor.\n",
      "41\n",
      "44\n",
      "54\n",
      "100\n",
      "104\n",
      "80\n",
      "57\n",
      "49\n",
      "186\n",
      "226\n",
      "38\n",
      "78\n",
      "111\n",
      "58\n",
      "116\n",
      "115\n",
      "55\n",
      "58\n",
      "41\n",
      "106\n",
      "34\n",
      "25\n",
      "1\n",
      "\n",
      "72\n",
      "31\n",
      "50\n",
      "79\n",
      "135\n",
      "15\n",
      "171\n",
      "64\n",
      "190\n",
      "94\n",
      "30\n",
      "212\n",
      "107\n",
      "39\n",
      "115\n",
      "58\n",
      "206\n",
      "27\n",
      "1\n",
      "\n",
      "123\n",
      "48\n",
      "86\n",
      "51\n",
      "134\n",
      "52\n",
      "34\n",
      "74\n",
      "190\n",
      "76\n",
      "164\n",
      "84\n",
      "111\n",
      "54\n",
      "109\n",
      "20\n",
      "121\n",
      "105\n",
      "129\n",
      "91\n",
      "74\n",
      "74\n",
      "110\n",
      "31\n",
      "49\n",
      "25\n",
      "50\n",
      "58\n",
      "76\n",
      "14\n",
      "43\n",
      "52\n",
      "48\n",
      "7\n",
      "The Noro virus really really sucks. (England)\n",
      "57\n",
      "32\n",
      "38\n",
      "35\n",
      "33\n",
      "51\n",
      "60\n",
      "33\n",
      "52\n",
      "108\n",
      "56\n",
      "26\n",
      "26\n",
      "42\n",
      "99\n",
      "20\n",
      "238\n",
      "148\n",
      "31\n",
      "72\n",
      "73\n",
      "54\n",
      "90\n",
      "21\n",
      "35\n",
      "71\n",
      "56\n",
      "89\n",
      "90\n",
      "46\n",
      "25\n",
      "70\n",
      "33\n",
      "17\n",
      "61\n",
      "78\n",
      "45\n",
      "42\n",
      "19\n",
      "123\n",
      "95\n",
      "63\n",
      "98\n",
      "37\n",
      "3\n",
      "Anyone generous enough? :)\n",
      "61\n",
      "64\n",
      "244\n",
      "51\n",
      "47\n",
      "150\n",
      "24\n",
      "70\n",
      "50\n",
      "115\n",
      "87\n",
      "95\n",
      "112\n",
      "103\n",
      "74\n",
      "176\n",
      "37\n",
      "202\n",
      "55\n",
      "54\n",
      "112\n",
      "25\n",
      "119\n",
      "156\n",
      "40\n",
      "136\n",
      "68\n",
      "388\n",
      "62\n",
      "67\n",
      "53\n",
      "176\n",
      "4\n",
      "Please and thank you!\n",
      "31\n",
      "60\n",
      "118\n",
      "143\n",
      "134\n",
      "46\n",
      "58\n",
      "7\n",
      "CAN WE STILL CELEBRATE WITH A PIZZA???\n",
      "58\n",
      "54\n",
      "68\n",
      "45\n",
      "58\n",
      "104\n",
      "55\n",
      "169\n",
      "115\n",
      "71\n",
      "42\n",
      "157\n",
      "132\n",
      "22\n",
      "140\n",
      "53\n",
      "16\n",
      "71\n",
      "180\n",
      "80\n",
      "4\n",
      "Where's my pizza?\n",
      "56\n",
      "36\n",
      "21\n",
      "11\n",
      "111\n",
      "159\n",
      "105\n",
      "17\n",
      "45\n",
      "49\n",
      "104\n",
      "80\n",
      "52\n",
      "106\n",
      "172\n",
      "42\n",
      "94\n",
      "33\n",
      "62\n",
      "58\n",
      "83\n",
      "76\n",
      "64\n",
      "76\n",
      "81\n",
      "82\n",
      "175\n",
      "129\n",
      "24\n",
      "102\n",
      "44\n",
      "51\n",
      "11\n",
      "45\n",
      "34\n",
      "33\n",
      "64\n",
      "75\n",
      "306\n",
      "23\n",
      "43\n",
      "152\n",
      "70\n",
      "15\n",
      "71\n",
      "34\n",
      "12\n",
      "39\n",
      "67\n",
      "127\n",
      "44\n",
      "110\n",
      "209\n",
      "131\n",
      "122\n",
      "130\n",
      "14\n",
      "48\n",
      "34\n",
      "19\n",
      "40\n",
      "42\n",
      "92\n",
      "28\n",
      "134\n",
      "88\n",
      "142\n",
      "67\n",
      "107\n",
      "1\n",
      "\n",
      "24\n",
      "1\n",
      "\n",
      "58\n",
      "1\n",
      "\n",
      "158\n",
      "336\n",
      "161\n",
      "143\n",
      "30\n",
      "41\n",
      "116\n",
      "1\n",
      "\n",
      "53\n",
      "22\n",
      "32\n",
      "3\n",
      "Stupid cracked monitor.\n",
      "69\n",
      "82\n",
      "39\n",
      "66\n",
      "11\n",
      "62\n",
      "44\n",
      "100\n",
      "32\n",
      "65\n",
      "28\n",
      "51\n",
      "214\n",
      "39\n",
      "25\n",
      "44\n",
      "102\n",
      "2\n",
      "thx bros\n",
      "51\n",
      "88\n",
      "49\n",
      "27\n",
      "16\n",
      "15\n",
      "179\n",
      "118\n",
      "102\n",
      "57\n",
      "35\n",
      "76\n",
      "77\n",
      "37\n",
      "39\n",
      "75\n",
      "1\n",
      "\n",
      "77\n",
      "63\n",
      "151\n",
      "57\n",
      "37\n",
      "79\n",
      "76\n",
      "1\n",
      "\n",
      "83\n",
      "90\n",
      "171\n",
      "1\n",
      "\n",
      "7\n",
      "I would love you forever and ever!\n",
      "191\n",
      "90\n",
      "61\n",
      "1\n",
      "\n",
      "69\n",
      "75\n",
      "1\n",
      "\n",
      "113\n",
      "47\n",
      "94\n",
      "11\n",
      "105\n",
      "93\n",
      "66\n",
      "42\n",
      "40\n",
      "62\n",
      "31\n",
      "111\n",
      "162\n",
      "50\n",
      "191\n",
      "98\n",
      "70\n",
      "75\n",
      "51\n",
      "43\n",
      "12\n",
      "1\n",
      "\n",
      "178\n",
      "52\n",
      "26\n",
      "23\n",
      "574\n",
      "113\n",
      "66\n",
      "15\n",
      "23\n",
      "66\n",
      "87\n",
      "33\n",
      "34\n",
      "73\n",
      "34\n",
      "95\n",
      "20\n",
      "18\n",
      "20\n",
      "97\n",
      "18\n",
      "40\n",
      "92\n",
      "82\n",
      "31\n",
      "77\n",
      "100\n",
      "133\n",
      "38\n",
      "79\n",
      "30\n",
      "104\n",
      "85\n",
      "140\n",
      "22\n",
      "27\n",
      "14\n",
      "41\n",
      "86\n",
      "32\n",
      "27\n",
      "905\n",
      "52\n",
      "47\n",
      "72\n",
      "69\n",
      "69\n",
      "47\n",
      "9\n",
      "I'll pay it forward when I have money\n",
      "52\n",
      "102\n",
      "92\n",
      "32\n",
      "18\n",
      "66\n",
      "204\n",
      "21\n",
      "93\n",
      "311\n",
      "28\n",
      "77\n",
      "130\n",
      "101\n",
      "284\n",
      "42\n",
      "63\n",
      "46\n",
      "98\n",
      "60\n",
      "49\n",
      "30\n",
      "132\n",
      "21\n",
      "6\n",
      "http://i.imgur.com/DxyE3.jpg\n",
      "14\n",
      "61\n",
      "16\n",
      "23\n",
      "70\n",
      "41\n",
      "92\n",
      "31\n",
      "23\n",
      "120\n",
      "224\n",
      "88\n",
      "108\n",
      "136\n",
      "75\n",
      "153\n",
      "71\n",
      "120\n",
      "74\n",
      "38\n",
      "34\n",
      "113\n",
      "17\n",
      "16\n",
      "54\n",
      "64\n",
      "107\n",
      "77\n",
      "44\n",
      "242\n",
      "120\n",
      "53\n",
      "20\n",
      "1\n",
      "\n",
      "19\n",
      "34\n",
      "43\n",
      "70\n",
      "73\n",
      "16\n",
      "62\n",
      "101\n",
      "57\n",
      "108\n",
      "48\n",
      "57\n",
      "144\n",
      "49\n",
      "139\n",
      "210\n",
      "17\n",
      "87\n",
      "30\n",
      "67\n",
      "81\n",
      "87\n",
      "222\n",
      "45\n",
      "44\n",
      "56\n",
      "145\n",
      "79\n",
      "23\n",
      "39\n",
      "95\n",
      "39\n",
      "144\n",
      "88\n",
      "56\n",
      "50\n",
      "59\n",
      "39\n",
      "39\n",
      "112\n",
      "37\n",
      "105\n",
      "74\n",
      "28\n",
      "40\n",
      "74\n",
      "16\n",
      "35\n",
      "1\n",
      "\n",
      "16\n",
      "16\n",
      "78\n",
      "52\n",
      "115\n",
      "32\n",
      "142\n",
      "66\n",
      "60\n",
      "95\n",
      "78\n",
      "69\n",
      "71\n",
      "84\n",
      "96\n",
      "165\n",
      "15\n",
      "57\n",
      "95\n",
      "43\n",
      "72\n",
      "38\n",
      "28\n",
      "84\n",
      "70\n",
      "10\n",
      "I will certainly repay the favor when I get paid (:\n",
      "43\n",
      "104\n",
      "132\n",
      "124\n",
      "84\n",
      "14\n",
      "76\n",
      "19\n",
      "53\n",
      "190\n",
      "179\n",
      "59\n",
      "95\n",
      "35\n",
      "32\n",
      "26\n",
      "47\n",
      "29\n",
      "76\n",
      "59\n",
      "130\n",
      "93\n",
      "56\n",
      "84\n",
      "57\n",
      "47\n",
      "52\n",
      "114\n",
      "4\n",
      "Help I'm hungry!!\n",
      "137\n",
      "72\n",
      "29\n",
      "116\n",
      "39\n",
      "110\n",
      "15\n",
      "302\n",
      "33\n",
      "70\n",
      "38\n",
      "90\n",
      "77\n",
      "50\n",
      "218\n",
      "23\n",
      "20\n",
      "105\n",
      "31\n",
      "84\n",
      "60\n",
      "81\n",
      "441\n",
      "49\n",
      "81\n",
      "81\n",
      "55\n",
      "33\n",
      "13\n",
      "61\n",
      "19\n",
      "57\n",
      "44\n",
      "31\n",
      "41\n",
      "47\n",
      "287\n",
      "57\n",
      "52\n",
      "1\n",
      "\n",
      "44\n",
      "69\n",
      "75\n",
      "155\n",
      "80\n",
      "329\n",
      "26\n",
      "166\n",
      "52\n",
      "184\n",
      "19\n",
      "180\n",
      "40\n",
      "164\n",
      "12\n",
      "68\n",
      "90\n",
      "270\n",
      "85\n",
      "52\n",
      "140\n",
      "99\n",
      "35\n",
      "51\n",
      "118\n",
      "53\n",
      "46\n",
      "57\n",
      "12\n",
      "19\n",
      "115\n",
      "17\n",
      "131\n",
      "36\n",
      "249\n",
      "60\n",
      "5\n",
      "A pizza would be lovely\n",
      "67\n",
      "18\n",
      "44\n",
      "73\n",
      "40\n",
      "75\n",
      "165\n",
      "45\n",
      "117\n",
      "57\n",
      "31\n",
      "45\n",
      "47\n",
      "53\n",
      "82\n",
      "82\n",
      "60\n",
      "31\n",
      "58\n",
      "97\n",
      "126\n",
      "102\n",
      "30\n",
      "73\n",
      "27\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "299\n",
      "75\n",
      "111\n",
      "113\n",
      "42\n",
      "162\n",
      "31\n",
      "108\n",
      "164\n",
      "67\n",
      "21\n",
      "2\n",
      "Tautological nom.\n",
      "67\n",
      "40\n",
      "188\n",
      "33\n",
      "76\n",
      "59\n",
      "18\n",
      "279\n",
      "42\n",
      "29\n",
      "1\n",
      "\n",
      "61\n",
      "12\n",
      "52\n",
      "110\n",
      "582\n",
      "83\n",
      "67\n",
      "64\n",
      "42\n",
      "86\n",
      "57\n",
      "7\n",
      "Haven't had pizza in a while\n",
      "180\n",
      "85\n",
      "66\n",
      "131\n",
      "280\n",
      "70\n",
      "80\n",
      "65\n",
      "46\n",
      "44\n",
      "38\n",
      "131\n",
      "54\n",
      "87\n",
      "87\n",
      "97\n",
      "107\n",
      "8\n",
      "Willing to respond with creative photography of pizza.\n",
      "70\n",
      "397\n",
      "118\n",
      "1\n",
      "\n",
      "102\n",
      "61\n",
      "106\n",
      "60\n",
      "55\n",
      "106\n",
      "99\n",
      "30\n",
      "77\n",
      "39\n",
      "112\n",
      "56\n",
      "79\n",
      "90\n",
      "45\n",
      "86\n",
      "33\n",
      "103\n",
      "275\n",
      "44\n",
      "79\n",
      "162\n",
      "88\n",
      "71\n",
      "32\n",
      "62\n",
      "54\n",
      "38\n",
      "95\n",
      "71\n",
      "101\n",
      "210\n",
      "47\n",
      "16\n",
      "66\n",
      "22\n",
      "19\n",
      "93\n",
      "190\n",
      "1\n",
      "\n",
      "49\n",
      "91\n",
      "47\n",
      "24\n",
      "22\n",
      "25\n",
      "85\n",
      "23\n",
      "34\n",
      "45\n",
      "89\n",
      "55\n",
      "69\n",
      "20\n",
      "1\n",
      "\n",
      "33\n",
      "47\n",
      "196\n",
      "45\n",
      "62\n",
      "118\n",
      "118\n",
      "34\n",
      "19\n",
      "35\n",
      "77\n",
      "219\n",
      "92\n",
      "45\n",
      "39\n",
      "108\n",
      "19\n",
      "18\n",
      "37\n",
      "171\n",
      "115\n",
      "58\n",
      "129\n",
      "33\n",
      "53\n",
      "66\n",
      "49\n",
      "1\n",
      "\n",
      "19\n",
      "36\n",
      "159\n",
      "29\n",
      "51\n",
      "69\n",
      "16\n",
      "62\n",
      "61\n",
      "399\n",
      "50\n",
      "75\n",
      "5\n",
      "I just want a pizza :]\n",
      "22\n",
      "63\n",
      "83\n",
      "43\n",
      "121\n",
      "19\n",
      "118\n",
      "1\n",
      "\n",
      "89\n",
      "54\n",
      "82\n",
      "72\n",
      "30\n",
      "112\n",
      "23\n",
      "89\n",
      "95\n",
      "136\n",
      "82\n",
      "27\n",
      "21\n",
      "23\n",
      "72\n",
      "55\n",
      "11\n",
      "107\n",
      "77\n",
      "48\n",
      "104\n",
      "103\n",
      "85\n",
      "37\n",
      "8\n",
      "Thank you so much for the pizza Trisha!\n",
      "47\n",
      "1\n",
      "\n",
      "57\n",
      "65\n",
      "73\n",
      "28\n",
      "22\n",
      "124\n",
      "52\n",
      "62\n",
      "45\n",
      "48\n",
      "83\n",
      "144\n",
      "1\n",
      "\n",
      "96\n",
      "32\n",
      "143\n",
      "43\n",
      "125\n",
      "28\n",
      "150\n",
      "76\n",
      "151\n",
      "113\n",
      "39\n",
      "19\n",
      "1\n",
      "\n",
      "69\n",
      "82\n",
      "4\n",
      "I live in Ohio\n",
      "108\n",
      "146\n",
      "56\n",
      "108\n",
      "4\n",
      "Just a Hungry student :)\n",
      "112\n",
      "422\n",
      "76\n",
      "69\n",
      "23\n",
      "33\n",
      "1\n",
      "\n",
      "98\n",
      "176\n",
      "5\n",
      "I'm hungry.\n",
      "\n",
      "Atlanta, GA\n",
      "44\n",
      "47\n",
      "47\n",
      "181\n",
      "85\n",
      "48\n",
      "111\n",
      "55\n",
      "234\n",
      "141\n",
      "48\n",
      "32\n",
      "90\n",
      "17\n",
      "49\n",
      "9\n",
      "unemployed, not eating tonight, thought id at least try.\n",
      "17\n",
      "93\n",
      "34\n",
      "41\n",
      "1\n",
      "\n",
      "50\n",
      "10\n",
      "I promise to repay the favor in the near future.  \n",
      "86\n",
      "78\n",
      "100\n",
      "44\n",
      "191\n",
      "194\n",
      "136\n",
      "32\n",
      "136\n",
      "113\n",
      "38\n",
      "219\n",
      "54\n",
      "32\n",
      "39\n",
      "99\n",
      "91\n",
      "186\n",
      "147\n",
      "23\n",
      "128\n",
      "115\n",
      "28\n",
      "43\n",
      "59\n",
      "65\n",
      "16\n",
      "13\n",
      "44\n",
      "2\n",
      "Read: hungry :/\n",
      "84\n",
      "33\n",
      "120\n",
      "178\n",
      "21\n",
      "78\n",
      "213\n",
      "45\n",
      "76\n",
      "51\n",
      "28\n",
      "62\n",
      "175\n",
      "259\n",
      "229\n",
      "32\n",
      "83\n",
      "259\n",
      "47\n",
      "191\n",
      "19\n",
      "378\n",
      "25\n",
      "91\n",
      "13\n",
      "65\n",
      "44\n",
      "29\n",
      "60\n",
      "72\n",
      "53\n",
      "13\n",
      "1\n",
      "\n",
      "58\n",
      "23\n",
      "68\n",
      "10\n",
      "Will return the favor to a random person on reddit \n",
      "1\n",
      "\n",
      "25\n",
      "19\n",
      "69\n",
      "48\n",
      "38\n",
      "50\n",
      "87\n",
      "37\n",
      "106\n",
      "1\n",
      "\n",
      "100\n",
      "15\n",
      "52\n",
      "42\n",
      "93\n",
      "1\n",
      "\n",
      "42\n",
      "12\n",
      "5\n",
      "[Received]   Big THANKS to katzmcn\n",
      "\n",
      "98\n",
      "34\n",
      "230\n",
      "59\n",
      "56\n",
      "32\n",
      "21\n",
      "61\n",
      "88\n",
      "52\n",
      "159\n",
      "93\n",
      "166\n",
      "57\n",
      "4\n",
      "thanks in advance guys! \n",
      "57\n",
      "56\n",
      "107\n",
      "37\n",
      "109\n",
      "94\n",
      "244\n",
      "87\n",
      "13\n",
      "19\n",
      "43\n",
      "181\n",
      "104\n",
      "40\n",
      "43\n",
      "26\n",
      "129\n",
      "82\n",
      "6\n",
      "But i would love a pie.\n",
      "82\n",
      "38\n",
      "37\n",
      "80\n",
      "1\n",
      "\n",
      "83\n",
      "58\n",
      "6\n",
      "Would appreciate anything, thanks so much.\n",
      "1\n",
      "\n",
      "68\n",
      "86\n",
      "90\n",
      "53\n",
      "25\n",
      "80\n",
      "86\n",
      "85\n",
      "45\n",
      "37\n",
      "70\n",
      "3\n",
      "Ottawa Ontario, Canada\n",
      "32\n",
      "67\n",
      "220\n",
      "50\n",
      "60\n",
      "211\n",
      "69\n",
      "66\n",
      "76\n",
      "26\n",
      "89\n",
      "497\n",
      "40\n",
      "15\n",
      "8\n",
      "Hungry...no money...i'll pay it forward.\n",
      "62\n",
      "57\n",
      "49\n",
      "324\n",
      "44\n",
      "22\n",
      "51\n",
      "50\n",
      "37\n",
      "46\n",
      "152\n",
      "26\n",
      "131\n",
      "85\n",
      "1\n",
      "\n",
      "46\n",
      "84\n",
      "162\n",
      "15\n",
      "13\n",
      "30\n",
      "109\n",
      "161\n",
      "36\n",
      "149\n",
      "106\n",
      "61\n",
      "113\n",
      "23\n",
      "55\n",
      "38\n",
      "56\n",
      "95\n",
      "52\n",
      "148\n",
      "45\n",
      "33\n",
      "21\n",
      "75\n",
      "32\n",
      "108\n",
      "48\n",
      "111\n",
      "69\n",
      "205\n",
      "18\n",
      "28\n",
      "97\n",
      "291\n",
      "98\n",
      "24\n",
      "275\n",
      "96\n",
      "142\n",
      "1435\n",
      "62\n",
      "30\n",
      "45\n",
      "96\n",
      "36\n",
      "16\n",
      "32\n",
      "33\n",
      "64\n",
      "85\n",
      "37\n",
      "59\n",
      "64\n",
      "6\n",
      "Just could really use a pizza. \n",
      "38\n",
      "79\n",
      "79\n",
      "33\n",
      "62\n",
      "38\n",
      "41\n",
      "108\n",
      "36\n",
      "73\n",
      "26\n",
      "52\n",
      "92\n",
      "78\n",
      "62\n",
      "36\n",
      "73\n",
      "57\n",
      "17\n",
      "89\n",
      "110\n",
      "39\n",
      "24\n",
      "72\n",
      "1\n",
      "\n",
      "58\n",
      "38\n",
      "91\n",
      "123\n",
      "75\n",
      "86\n",
      "1\n",
      "\n",
      "35\n",
      "119\n",
      "49\n",
      "37\n",
      "104\n",
      "101\n",
      "91\n",
      "150\n",
      "84\n",
      "102\n",
      "103\n",
      "1\n",
      "\n",
      "64\n",
      "271\n",
      "79\n",
      "93\n",
      "38\n",
      "132\n",
      "18\n",
      "55\n",
      "58\n",
      "35\n",
      "320\n",
      "59\n",
      "70\n",
      "34\n",
      "146\n",
      "59\n",
      "18\n",
      "123\n",
      "28\n",
      "12\n",
      "14\n",
      "63\n",
      "1\n",
      "\n",
      "134\n",
      "199\n",
      "124\n",
      "4\n",
      "Praying for a RAoP.\n",
      "28\n",
      "1\n",
      "\n",
      "152\n",
      "24\n",
      "94\n",
      "82\n",
      "1\n",
      "\n",
      "58\n",
      "167\n",
      "90\n",
      "120\n",
      "52\n",
      "89\n",
      "76\n",
      "27\n",
      "78\n",
      "167\n",
      "71\n",
      "78\n",
      "75\n",
      "50\n",
      "47\n",
      "115\n",
      "52\n",
      "26\n",
      "348\n",
      "1\n",
      "\n",
      "33\n",
      "1235\n",
      "10\n",
      "Being a girl isn't fun sometimes. I need pizza.\n",
      "106\n",
      "124\n",
      "78\n",
      "54\n",
      "34\n",
      "103\n",
      "213\n",
      "116\n",
      "75\n",
      "25\n",
      "45\n",
      "5\n",
      "Will pay it forward asap.\n",
      "60\n",
      "73\n",
      "44\n",
      "12\n",
      "60\n",
      "73\n",
      "27\n",
      "22\n",
      "85\n",
      "23\n",
      "45\n",
      "60\n",
      "1\n",
      "\n",
      "71\n",
      "104\n",
      "27\n",
      "225\n",
      "46\n",
      "29\n",
      "115\n",
      "121\n",
      "75\n",
      "147\n",
      "14\n",
      "50\n",
      "151\n",
      "186\n",
      "1\n",
      "\n",
      "172\n",
      "91\n",
      "47\n",
      "423\n",
      "51\n",
      "32\n",
      "38\n",
      "15\n",
      "77\n",
      "64\n",
      "14\n",
      "57\n",
      "80\n",
      "30\n",
      "213\n",
      "44\n",
      "17\n",
      "38\n",
      "21\n",
      "33\n",
      "75\n",
      "19\n",
      "25\n",
      "175\n",
      "23\n",
      "21\n",
      "35\n",
      "201\n",
      "107\n",
      "88\n",
      "88\n",
      "22\n",
      "33\n",
      "35\n",
      "107\n",
      "65\n",
      "52\n",
      "76\n",
      "37\n",
      "108\n",
      "59\n",
      "94\n",
      "7\n",
      "and I'm all out of bubblegum.\n",
      "15\n",
      "4\n",
      "Edit: adding location / California \n",
      "32\n",
      "34\n",
      "2\n",
      "Raleigh, NC\n",
      "183\n",
      "40\n",
      "149\n",
      "24\n",
      "37\n",
      "33\n",
      "6\n",
      "Gonna be a long long night\n",
      "84\n",
      "131\n",
      "61\n",
      "106\n",
      "48\n",
      "31\n",
      "122\n",
      "50\n",
      "90\n",
      "68\n",
      "53\n",
      "55\n",
      "76\n",
      "407\n",
      "94\n",
      "228\n",
      "43\n",
      "1\n",
      "\n",
      "120\n",
      "74\n",
      "47\n",
      "38\n",
      "56\n",
      "42\n",
      "89\n",
      "22\n",
      "149\n",
      "33\n",
      "181\n",
      "27\n",
      "67\n",
      "96\n",
      "151\n",
      "215\n",
      "62\n",
      "68\n",
      "34\n",
      "263\n",
      "16\n",
      "32\n",
      "31\n",
      "15\n",
      "32\n",
      "28\n",
      "87\n",
      "41\n",
      "102\n",
      "24\n",
      "25\n",
      "75\n",
      "55\n",
      "68\n",
      "80\n",
      "95\n",
      "102\n",
      "118\n",
      "343\n",
      "33\n",
      "91\n",
      "74\n",
      "23\n",
      "25\n",
      "177\n",
      "252\n",
      "55\n",
      "65\n",
      "42\n",
      "62\n",
      "10\n",
      "It's my awesome birthday. Help a brother out plox?\n",
      "121\n",
      "5\n",
      "Goes great with Jack Daniels! :)\n",
      "46\n",
      "64\n",
      "136\n",
      "52\n",
      "128\n",
      "79\n",
      "75\n",
      "60\n",
      "48\n",
      "32\n",
      "37\n",
      "50\n",
      "36\n",
      "29\n",
      "32\n",
      "105\n",
      "57\n",
      "144\n",
      "15\n",
      "17\n",
      "73\n",
      "69\n",
      "60\n",
      "61\n",
      "6\n",
      "Would like to surprise my son.  :)\n",
      "110\n",
      "70\n",
      "350\n",
      "92\n",
      "44\n",
      "106\n",
      "3\n",
      "OP will deliver.\n",
      "77\n",
      "66\n",
      "37\n",
      "49\n",
      "26\n",
      "120\n",
      "57\n",
      "29\n",
      "137\n",
      "149\n",
      "16\n",
      "74\n",
      "48\n",
      "53\n",
      "86\n",
      "174\n",
      "45\n",
      "1\n",
      "*\n",
      "31\n",
      "8\n",
      "How about a pizza to break the ice?\n",
      "27\n",
      "79\n",
      "50\n",
      "95\n",
      "140\n",
      "67\n",
      "24\n",
      "90\n",
      "87\n",
      "17\n",
      "114\n",
      "65\n",
      "73\n",
      "98\n",
      "29\n",
      "20\n",
      "24\n",
      "112\n",
      "55\n",
      "35\n",
      "51\n",
      "59\n",
      "107\n",
      "39\n",
      "1\n",
      "\n",
      "112\n",
      "15\n",
      "83\n",
      "23\n",
      "115\n",
      "40\n",
      "57\n",
      "85\n",
      "110\n",
      "165\n",
      "16\n",
      "137\n",
      "86\n",
      "78\n",
      "59\n",
      "11\n",
      "52\n",
      "70\n",
      "23\n",
      "120\n",
      "52\n",
      "31\n",
      "83\n",
      "139\n",
      "58\n",
      "50\n",
      "58\n",
      "89\n",
      "28\n",
      "99\n",
      "27\n",
      "57\n",
      "78\n",
      "81\n",
      "59\n",
      "1\n",
      "\n",
      "26\n",
      "192\n",
      "98\n",
      "271\n",
      "32\n",
      "191\n",
      "103\n",
      "42\n",
      "149\n",
      "46\n",
      "84\n",
      "58\n",
      "109\n",
      "182\n",
      "61\n",
      "78\n",
      "43\n",
      "139\n",
      "101\n",
      "261\n",
      "57\n",
      "152\n",
      "769\n",
      "267\n",
      "18\n",
      "55\n",
      "53\n",
      "10\n",
      "Would greatly appreciate it, sucks seeing her so bummed out.\n",
      "67\n",
      "83\n",
      "15\n",
      "129\n",
      "53\n",
      "58\n",
      "28\n",
      "131\n",
      "134\n",
      "57\n",
      "77\n",
      "76\n",
      "31\n",
      "25\n",
      "1\n",
      "\n",
      "91\n",
      "1\n",
      "\n",
      "204\n",
      "99\n",
      "103\n",
      "7\n",
      "Would like to have a pizza tonight\n",
      "56\n",
      "89\n",
      "41\n",
      "47\n",
      "49\n",
      "97\n",
      "159\n",
      "52\n",
      "114\n",
      "56\n",
      "86\n",
      "3\n",
      "PIZZA ME.\n",
      "[](/omg)\n",
      "\n",
      "211\n",
      "77\n",
      "37\n",
      "318\n",
      "41\n",
      "58\n",
      "88\n",
      "123\n",
      "173\n",
      "52\n",
      "46\n",
      "37\n",
      "105\n",
      "57\n",
      "64\n",
      "54\n",
      "29\n",
      "49\n",
      "81\n",
      "28\n",
      "30\n",
      "32\n",
      "62\n",
      "118\n",
      "85\n",
      "26\n",
      "114\n",
      "21\n",
      "69\n",
      "3\n",
      "Puh puh pleaseeeee\n",
      "91\n",
      "115\n",
      "57\n",
      "63\n",
      "32\n",
      "85\n",
      "59\n",
      "96\n",
      "33\n",
      "106\n",
      "2\n",
      "Thanks, Redditors\n",
      "30\n",
      "54\n",
      "479\n",
      "29\n",
      "20\n",
      "31\n",
      "41\n",
      "88\n",
      "70\n",
      "74\n",
      "70\n",
      "40\n",
      "55\n",
      "24\n",
      "78\n",
      "100\n",
      "116\n",
      "199\n",
      "112\n",
      "76\n",
      "106\n",
      "32\n",
      "210\n",
      "5\n",
      "In Canada by the way. \n",
      "146\n",
      "185\n",
      "107\n",
      "48\n",
      "186\n",
      "79\n",
      "20\n",
      "70\n",
      "54\n",
      "34\n",
      "41\n",
      "44\n",
      "44\n",
      "40\n",
      "341\n",
      "74\n",
      "66\n",
      "56\n",
      "42\n",
      "39\n",
      "69\n",
      "35\n",
      "29\n",
      "28\n",
      "32\n",
      "48\n",
      "426\n",
      "176\n",
      "7\n",
      "I will owe you the world. Thanks.\n",
      "51\n",
      "19\n",
      "28\n",
      "59\n",
      "96\n",
      "7\n",
      "References:\n",
      "Robot_Legs, \"Hungry, Hungry Roommates\", (December, 2012)\n",
      "112\n",
      "67\n",
      "90\n",
      "71\n",
      "87\n",
      "42\n",
      "53\n",
      "55\n",
      "59\n",
      "85\n",
      "268\n",
      "30\n",
      "51\n",
      "16\n",
      "1\n",
      "\n",
      "38\n",
      "267\n",
      "23\n",
      "54\n",
      "64\n",
      "37\n",
      "167\n",
      "117\n",
      "123\n",
      "125\n",
      "54\n",
      "55\n",
      "51\n",
      "84\n",
      "15\n",
      "144\n",
      "31\n",
      "36\n",
      "72\n",
      "18\n",
      "137\n",
      "58\n",
      "83\n",
      "61\n",
      "74\n",
      "1\n",
      "\n",
      "103\n",
      "106\n",
      "59\n",
      "141\n",
      "60\n",
      "209\n",
      "48\n",
      "69\n",
      "22\n",
      "73\n",
      "122\n",
      "102\n",
      "22\n",
      "16\n",
      "133\n",
      "36\n",
      "39\n",
      "57\n",
      "58\n",
      "55\n",
      "291\n",
      "99\n",
      "69\n",
      "216\n",
      "9\n",
      "I love reading Wired, but this is something else.\n",
      "25\n",
      "111\n",
      "184\n",
      "126\n",
      "14\n",
      "65\n",
      "122\n",
      "91\n",
      "39\n",
      "65\n",
      "235\n",
      "1\n",
      "*\n",
      "26\n",
      "74\n",
      "189\n",
      "172\n",
      "53\n",
      "51\n",
      "1\n",
      "\n",
      "16\n",
      "96\n",
      "36\n",
      "102\n",
      "37\n",
      "48\n",
      "34\n",
      "137\n",
      "30\n",
      "108\n",
      "66\n",
      "148\n",
      "55\n",
      "80\n",
      "64\n",
      "135\n",
      "144\n",
      "39\n",
      "65\n",
      "55\n",
      "21\n",
      "77\n",
      "131\n",
      "95\n",
      "51\n",
      "58\n",
      "191\n",
      "92\n",
      "70\n",
      "49\n",
      "38\n",
      "56\n",
      "6\n",
      "Would be a huge lifesaver tonight......\n",
      "144\n",
      "19\n",
      "44\n",
      "67\n",
      "174\n",
      "121\n",
      "41\n",
      "95\n",
      "64\n",
      "53\n",
      "83\n",
      "35\n",
      "85\n",
      "157\n",
      "95\n",
      "111\n",
      "48\n",
      "25\n",
      "61\n",
      "160\n",
      "31\n",
      "22\n",
      "69\n",
      "55\n",
      "256\n",
      "104\n",
      "109\n",
      "130\n",
      "36\n",
      "265\n",
      "108\n",
      "32\n",
      "48\n",
      "25\n",
      "130\n",
      "172\n",
      "61\n",
      "1\n",
      "\n",
      "219\n",
      "163\n",
      "157\n",
      "36\n",
      "122\n",
      "41\n",
      "43\n",
      "125\n",
      "32\n",
      "106\n",
      "128\n",
      "132\n",
      "65\n",
      "37\n",
      "52\n",
      "123\n",
      "50\n",
      "52\n",
      "43\n",
      "52\n",
      "54\n",
      "80\n",
      "209\n",
      "104\n",
      "22\n",
      "204\n",
      "40\n",
      "52\n",
      "25\n",
      "47\n",
      "14\n",
      "262\n",
      "228\n",
      "22\n",
      "86\n",
      "58\n",
      "65\n",
      "142\n",
      "95\n",
      "30\n",
      "237\n",
      "153\n",
      "64\n",
      "158\n",
      "94\n",
      "77\n",
      "23\n",
      "79\n",
      "60\n",
      "58\n",
      "91\n",
      "144\n",
      "39\n",
      "33\n",
      "63\n",
      "11\n",
      "150\n",
      "24\n",
      "45\n",
      "68\n",
      "109\n",
      "5\n",
      "How's everyone doing tonight?\n",
      "31\n",
      "186\n",
      "1\n",
      "\n",
      "36\n",
      "75\n",
      "56\n",
      "50\n",
      "199\n",
      "207\n",
      "1\n",
      "\n",
      "53\n",
      "128\n",
      "15\n",
      "17\n",
      "167\n",
      "132\n",
      "74\n",
      "95\n",
      "36\n",
      "1\n",
      "\n",
      "11\n",
      "54\n",
      "25\n",
      "65\n",
      "1\n",
      "\n",
      "328\n",
      "48\n",
      "120\n",
      "26\n",
      "15\n",
      "60\n",
      "13\n",
      "39\n",
      "92\n",
      "12\n",
      "57\n",
      "72\n",
      "55\n",
      "54\n",
      "57\n",
      "209\n",
      "1\n",
      "\n",
      "4\n",
      "http://www.mordours.com/\n",
      "38\n",
      "79\n",
      "122\n",
      "51\n",
      "71\n",
      "50\n",
      "26\n",
      "44\n",
      "143\n",
      "111\n",
      "11\n",
      "232\n",
      "53\n",
      "220\n",
      "80\n",
      "29\n",
      "60\n",
      "52\n",
      "72\n",
      "195\n",
      "97\n",
      "74\n",
      "87\n",
      "120\n",
      "254\n",
      "77\n",
      "38\n",
      "96\n",
      "63\n",
      "109\n",
      "22\n",
      "37\n",
      "197\n",
      "170\n",
      "149\n",
      "83\n",
      "32\n",
      "197\n",
      "100\n",
      "54\n",
      "39\n",
      "194\n",
      "58\n",
      "47\n",
      "120\n",
      "65\n",
      "79\n",
      "279\n",
      "135\n",
      "64\n",
      "161\n",
      "1\n",
      "\n",
      "118\n",
      "90\n",
      "134\n",
      "38\n",
      "61\n",
      "623\n",
      "14\n",
      "36\n",
      "47\n",
      "48\n",
      "47\n",
      "48\n",
      "76\n",
      "86\n",
      "59\n",
      "86\n",
      "45\n",
      "67\n",
      "15\n",
      "33\n",
      "69\n",
      "77\n",
      "30\n",
      "70\n",
      "120\n",
      "3\n",
      "Thanks in advance!\n",
      "132\n",
      "29\n",
      "41\n",
      "37\n",
      "1\n",
      "\n",
      "240\n",
      "5\n",
      "I'm in North Carolina.\n",
      "92\n",
      "46\n",
      "35\n",
      "48\n",
      "22\n",
      "52\n",
      "47\n",
      "64\n",
      "45\n",
      "60\n",
      "32\n",
      "23\n",
      "88\n",
      "35\n",
      "71\n",
      "59\n",
      "98\n",
      "62\n",
      "69\n",
      "35\n",
      "39\n",
      "82\n",
      "13\n",
      "261\n",
      "97\n",
      "413\n",
      "56\n",
      "245\n",
      "51\n",
      "61\n",
      "45\n",
      "100\n",
      "109\n",
      "55\n",
      "190\n",
      "76\n",
      "93\n",
      "1\n",
      "Test\n",
      "53\n",
      "61\n",
      "31\n",
      "50\n",
      "37\n",
      "195\n",
      "164\n",
      "70\n",
      "19\n",
      "102\n",
      "71\n",
      "431\n",
      "48\n",
      "17\n",
      "58\n",
      "52\n",
      "156\n",
      "55\n",
      "3\n",
      "Northern chicago area.\n",
      "170\n",
      "24\n",
      "20\n",
      "43\n",
      "59\n",
      "1\n",
      "pleaaase?\n",
      "40\n",
      "34\n",
      "123\n",
      "36\n",
      "110\n",
      "79\n",
      "19\n",
      "85\n",
      "23\n",
      "8\n",
      "This is my first RAOP Request! Thanks, dudes.\n",
      "536\n",
      "154\n",
      "89\n",
      "55\n",
      "366\n",
      "72\n",
      "129\n",
      "53\n",
      "58\n",
      "40\n",
      "54\n",
      "51\n",
      "50\n",
      "98\n",
      "82\n",
      "156\n",
      "6\n",
      "Hash partay needs pizza what up\n",
      "9\n",
      "Struggling to find employment. Would love a pepperoni pizza.\n",
      "49\n",
      "16\n",
      "1\n",
      "\n",
      "23\n",
      "33\n",
      "49\n",
      "174\n",
      "87\n",
      "1\n",
      "\n",
      "408\n",
      "91\n",
      "23\n",
      "70\n",
      "6\n",
      "Shit ima get downvoted to hell. \n",
      "51\n",
      "18\n",
      "103\n",
      "21\n",
      "124\n",
      "49\n",
      "64\n",
      "255\n",
      "49\n",
      "82\n",
      "42\n",
      "33\n",
      "22\n",
      "375\n",
      "67\n",
      "88\n",
      "207\n",
      "37\n",
      "138\n",
      "66\n",
      "57\n",
      "29\n",
      "58\n",
      "92\n",
      "64\n",
      "118\n",
      "46\n",
      "87\n",
      "14\n",
      "119\n",
      "77\n",
      "73\n",
      "151\n",
      "49\n",
      "59\n",
      "397\n",
      "25\n",
      "62\n",
      "63\n",
      "306\n",
      "141\n",
      "12\n",
      "62\n",
      "216\n",
      "63\n",
      "108\n",
      "62\n",
      "1\n",
      "\n",
      "51\n",
      "93\n",
      "80\n",
      "391\n",
      "117\n",
      "52\n",
      "47\n",
      "60\n",
      "20\n",
      "71\n",
      "128\n",
      "43\n",
      "233\n",
      "73\n",
      "86\n",
      "22\n",
      "203\n",
      "34\n",
      "55\n",
      "133\n",
      "48\n",
      "126\n",
      "55\n",
      "114\n",
      "17\n",
      "35\n",
      "139\n",
      "31\n",
      "80\n",
      "150\n",
      "52\n",
      "64\n",
      "161\n",
      "68\n",
      "177\n",
      "10\n",
      "Can someone make the first night here a bit easier?\n",
      "27\n",
      "59\n",
      "50\n",
      "115\n",
      "20\n",
      "73\n",
      "45\n",
      "141\n",
      "77\n",
      "52\n",
      "48\n",
      "7\n",
      "So, Reddit, want to prove him wrong?\n",
      "61\n",
      "112\n",
      "70\n",
      "114\n",
      "23\n",
      "60\n",
      "254\n",
      "225\n",
      "56\n",
      "56\n",
      "126\n",
      "34\n",
      "65\n",
      "1\n",
      "\n",
      "392\n",
      "185\n",
      "163\n",
      "44\n",
      "39\n",
      "86\n",
      "50\n",
      "21\n",
      "55\n",
      "40\n",
      "1\n",
      "\n",
      "167\n",
      "60\n",
      "71\n",
      "77\n",
      "78\n",
      "37\n",
      "29\n",
      "173\n",
      "59\n",
      "39\n",
      "57\n",
      "85\n",
      "38\n",
      "106\n",
      "42\n",
      "185\n",
      "187\n",
      "123\n",
      "71\n",
      "145\n",
      "83\n",
      "79\n",
      "33\n",
      "120\n",
      "9\n",
      "Much appreciated, i really have had a horrible week.\n",
      "74\n",
      "97\n",
      "84\n",
      "16\n",
      "503\n",
      "77\n",
      "44\n",
      "168\n",
      "11\n",
      "81\n",
      "73\n",
      "38\n",
      "59\n",
      "75\n",
      "106\n",
      "14\n",
      "17\n",
      "59\n",
      "51\n",
      "47\n",
      "47\n",
      "18\n",
      "54\n",
      "180\n",
      "47\n",
      "62\n",
      "18\n",
      "48\n",
      "27\n",
      "29\n",
      "52\n",
      "101\n",
      "18\n",
      "119\n",
      "54\n",
      "4\n",
      "Happy Birthday to Me\n",
      "1\n",
      "\n",
      "176\n",
      "61\n",
      "9\n",
      "Pretty please and thank you from me and Dog.\n",
      "14\n",
      "64\n",
      "76\n",
      "38\n",
      "62\n",
      "119\n",
      "120\n",
      "17\n",
      "34\n",
      "92\n",
      "1\n",
      "\n",
      "92\n",
      "25\n",
      "94\n",
      "25\n",
      "139\n",
      "134\n",
      "59\n",
      "118\n",
      "27\n",
      "242\n",
      "119\n",
      "136\n",
      "74\n",
      "49\n",
      "80\n",
      "27\n",
      "9\n",
      "Would much appreciate any who could fulfill this craving.\n",
      "\n",
      "1\n",
      "\n",
      "36\n",
      "66\n",
      "75\n",
      "49\n",
      "27\n",
      "383\n",
      "84\n",
      "162\n",
      "136\n",
      "98\n",
      "75\n",
      "51\n",
      "160\n",
      "26\n",
      "82\n",
      "40\n",
      "139\n",
      "44\n",
      "15\n",
      "48\n",
      "37\n",
      "126\n",
      "27\n",
      "116\n",
      "58\n",
      "91\n",
      "171\n",
      "24\n",
      "50\n",
      "88\n",
      "40\n",
      "35\n",
      "105\n",
      "44\n",
      "35\n",
      "41\n",
      "11\n",
      "11\n",
      "52\n",
      "81\n",
      "28\n",
      "112\n",
      "28\n",
      "82\n",
      "64\n",
      "1\n",
      "\n",
      "52\n",
      "92\n",
      "139\n",
      "92\n",
      "190\n",
      "90\n",
      "19\n",
      "40\n",
      "88\n",
      "72\n",
      "67\n",
      "100\n",
      "85\n",
      "83\n",
      "230\n",
      "22\n",
      "184\n",
      "119\n",
      "83\n",
      "110\n",
      "74\n",
      "18\n",
      "104\n",
      "91\n",
      "140\n",
      "33\n",
      "4\n",
      "I love you all\n",
      "62\n",
      "10\n",
      "Happy to pay it forward on friday :) Columbus, ohio here.\n",
      "153\n",
      "40\n",
      "53\n",
      "109\n",
      "78\n",
      "40\n",
      "77\n",
      "177\n",
      "77\n",
      "13\n",
      "190\n",
      "9\n",
      "[the desired pizza &lt;3](http://imgur.com/MFm5B)\n",
      "28\n",
      "1\n",
      "\n",
      "24\n",
      "87\n",
      "53\n",
      "39\n",
      "43\n",
      "295\n",
      "43\n",
      "25\n",
      "34\n",
      "146\n",
      "44\n",
      "131\n",
      "16\n",
      "71\n",
      "153\n",
      "28\n",
      "143\n",
      "40\n",
      "100\n",
      "71\n",
      "55\n",
      "71\n",
      "40\n",
      "91\n",
      "228\n",
      "62\n",
      "33\n",
      "47\n",
      "41\n",
      "31\n",
      "19\n",
      "108\n",
      "112\n",
      "100\n",
      "18\n",
      "136\n",
      "62\n",
      "65\n",
      "52\n",
      "122\n",
      "30\n",
      "52\n",
      "63\n",
      "33\n",
      "41\n",
      "99\n",
      "39\n",
      "102\n",
      "277\n",
      "122\n",
      "45\n",
      "47\n",
      "39\n",
      "169\n",
      "100\n",
      "74\n",
      "62\n",
      "99\n",
      "83\n",
      "10\n",
      "Third and final interview for a job tomorrow. Southaven, Mississippi\n",
      "66\n",
      "71\n",
      "16\n",
      "50\n",
      "439\n",
      "66\n",
      "75\n",
      "20\n",
      "51\n",
      "67\n",
      "39\n",
      "130\n",
      "79\n",
      "25\n",
      "26\n",
      "29\n",
      "119\n",
      "8\n",
      "Starving, no money, no food...please reach out.\n",
      "41\n",
      "67\n",
      "8\n",
      "I've been eating saltine crackers all day :/\n",
      "40\n",
      "54\n",
      "64\n",
      "30\n",
      "29\n",
      "18\n",
      "66\n",
      "27\n",
      "43\n",
      "6\n",
      "Could pizza it forward by sunday. \n",
      "25\n",
      "54\n",
      "145\n",
      "143\n",
      "31\n",
      "107\n",
      "58\n",
      "112\n",
      "64\n",
      "36\n",
      "75\n",
      "66\n",
      "66\n",
      "71\n",
      "1\n",
      "\n",
      "60\n",
      "4\n",
      "that is all. HALP!@#$%^%\n",
      "9\n",
      "It's been too long, I'll take anything! \n",
      "23\n",
      "9\n",
      "I'd love to celebrate via pizza lol (ky)\n",
      "123\n",
      "33\n",
      "204\n",
      "32\n",
      "261\n",
      "1\n",
      "\n",
      "19\n",
      "67\n",
      "75\n",
      "153\n",
      "83\n",
      "120\n",
      "46\n",
      "140\n",
      "81\n",
      "107\n",
      "18\n",
      "6\n",
      "Like title says, any pizza :D\n",
      "53\n",
      "1\n",
      "\n",
      "40\n",
      "108\n",
      "574\n",
      "74\n",
      "60\n",
      "66\n",
      "42\n",
      "34\n",
      "101\n",
      "75\n",
      "43\n",
      "67\n",
      "86\n",
      "69\n",
      "7\n",
      "Its raining and they would be stoked!\n",
      "44\n",
      "11\n",
      "12\n",
      "58\n",
      "24\n",
      "4\n",
      "My reddit cake day!\n",
      "66\n",
      "62\n",
      "83\n",
      "30\n",
      "84\n",
      "112\n",
      "56\n",
      "85\n",
      "47\n",
      "71\n",
      "93\n",
      "163\n",
      "259\n",
      "4\n",
      "Experiencing times of hunger :/\n",
      "61\n",
      "66\n",
      "1\n",
      "\n",
      "37\n",
      "87\n",
      "10\n",
      "I will be your friend.\n",
      "forever.\n",
      "and ever.\n",
      "\n",
      "&lt;3\n",
      "58\n",
      "30\n",
      "142\n",
      "27\n",
      "95\n",
      "80\n",
      "177\n",
      "29\n",
      "46\n",
      "49\n",
      "52\n",
      "10\n",
      "When I have the means I *will* pay it forward.\n",
      "47\n",
      "49\n",
      "1\n",
      "Closed:]\n",
      "46\n",
      "30\n",
      "37\n",
      "3\n",
      "I am hungry\n",
      "65\n",
      "113\n",
      "297\n",
      "13\n",
      "83\n",
      "59\n",
      "88\n",
      "24\n",
      "49\n",
      "52\n",
      "29\n",
      "79\n",
      "77\n",
      "19\n",
      "9\n",
      "Ill take only Domino's delivers though. Pwease :D\n",
      "225\n",
      "145\n",
      "36\n",
      "69\n",
      "77\n",
      "33\n",
      "63\n",
      "20\n",
      "105\n",
      "155\n",
      "8\n",
      "Thank you guys! I hope to get pizza! \n",
      "54\n",
      "76\n",
      "118\n",
      "1\n",
      "\n",
      "128\n",
      "48\n",
      "66\n",
      "34\n",
      "39\n",
      "45\n",
      "428\n",
      "88\n",
      "58\n",
      "47\n",
      "119\n",
      "90\n",
      "132\n",
      "188\n",
      "46\n",
      "16\n",
      "43\n",
      "31\n",
      "46\n",
      "9\n",
      "Please help!\n",
      "http://i.imgur.com/k4mZ7kR.png?1\n",
      "49\n",
      "104\n",
      "57\n",
      "86\n",
      "23\n",
      "44\n",
      "45\n",
      "77\n",
      "61\n",
      "15\n",
      "138\n",
      "110\n",
      "75\n",
      "45\n",
      "89\n",
      "54\n",
      "136\n",
      "36\n",
      "1\n",
      "\n",
      "80\n",
      "45\n",
      "42\n",
      "106\n",
      "249\n",
      "67\n",
      "49\n",
      "109\n",
      "46\n",
      "87\n",
      "172\n",
      "11\n",
      "43\n",
      "37\n",
      "293\n",
      "72\n",
      "104\n",
      "26\n",
      "149\n",
      "60\n",
      "81\n",
      "91\n",
      "20\n",
      "93\n",
      "148\n",
      "32\n",
      "36\n",
      "24\n",
      "93\n",
      "294\n",
      "73\n",
      "40\n",
      "129\n",
      "102\n",
      "61\n",
      "2\n",
      "Much appreciated. :)\n",
      "162\n",
      "142\n",
      "35\n",
      "254\n",
      "86\n",
      "72\n",
      "156\n",
      "37\n",
      "38\n",
      "72\n",
      "104\n",
      "94\n",
      "120\n",
      "51\n",
      "61\n",
      "61\n",
      "10\n",
      "Will most assuredly return the favor or pass it along!\n",
      "77\n",
      "41\n",
      "42\n",
      "27\n",
      "1\n",
      "\n",
      "74\n",
      "58\n",
      "39\n",
      "10\n",
      "just got the pizza! thank you soo much to oOBlackRabbitOo!!!\n",
      "150\n",
      "11\n",
      "591\n",
      "40\n",
      "55\n",
      "19\n",
      "34\n",
      "6\n",
      "im in philly area, 19128\n",
      "\n",
      "\n",
      "THANKS!\n",
      "91\n",
      "64\n",
      "33\n",
      "72\n",
      "42\n",
      "41\n",
      "130\n",
      "70\n",
      "25\n",
      "19\n",
      "1\n",
      ".....\n",
      "112\n",
      "29\n",
      "135\n",
      "114\n",
      "281\n",
      "28\n",
      "20\n",
      "114\n",
      "120\n",
      "126\n",
      "288\n",
      "23\n",
      "52\n",
      "36\n",
      "87\n",
      "73\n",
      "37\n",
      "121\n",
      "130\n",
      "43\n",
      "66\n",
      "45\n",
      "26\n",
      "51\n",
      "41\n",
      "68\n",
      "118\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "38\n",
      "65\n",
      "153\n",
      "36\n",
      "272\n",
      "35\n",
      "31\n",
      "69\n",
      "47\n",
      "58\n",
      "102\n",
      "166\n",
      "107\n",
      "202\n",
      "78\n",
      "8\n",
      "Family of 6 would LOVE a pizza gift!\n",
      "3\n",
      "Mwaahhh thanks. (WA)\n",
      "30\n",
      "44\n",
      "294\n",
      "123\n",
      "47\n",
      "66\n",
      "115\n",
      "77\n",
      "45\n",
      "74\n",
      "41\n",
      "177\n",
      "82\n",
      "15\n",
      "59\n",
      "65\n",
      "179\n",
      "88\n",
      "57\n",
      "63\n",
      "88\n",
      "118\n",
      "97\n",
      "49\n",
      "117\n",
      "90\n",
      "184\n",
      "177\n",
      "90\n",
      "77\n",
      "158\n",
      "179\n",
      "220\n",
      "15\n",
      "47\n",
      "73\n",
      "213\n",
      "165\n",
      "94\n",
      "48\n",
      "71\n",
      "79\n",
      "58\n",
      "61\n",
      "69\n",
      "25\n",
      "24\n",
      "114\n",
      "118\n",
      "187\n",
      "7\n",
      "Yeah title pretty much says it all.\n",
      "58\n",
      "12\n",
      "64\n",
      "22\n",
      "31\n",
      "106\n",
      "198\n",
      "80\n",
      "1\n",
      "\n",
      "114\n",
      "1\n",
      "\n",
      "34\n",
      "71\n",
      "75\n",
      "48\n",
      "45\n",
      "107\n",
      "4\n",
      "Edit: iEatPie got me.\n",
      "\n",
      "\n",
      "120\n",
      "1\n",
      "\n",
      "214\n",
      "100\n",
      "84\n",
      "128\n",
      "69\n",
      "274\n",
      "81\n",
      "73\n",
      "27\n",
      "129\n",
      "171\n",
      "38\n",
      "66\n",
      "35\n",
      "34\n",
      "47\n",
      "70\n",
      "45\n",
      "26\n",
      "41\n",
      "106\n",
      "116\n",
      "44\n",
      "81\n",
      "48\n",
      "192\n",
      "13\n",
      "75\n",
      "96\n",
      "67\n",
      "242\n",
      "3\n",
      "I love pizza\n",
      "70\n",
      "41\n",
      "137\n",
      "46\n",
      "46\n",
      "37\n",
      "54\n",
      "183\n",
      "68\n",
      "56\n",
      "88\n",
      "91\n",
      "1\n",
      "\n",
      "81\n",
      "35\n",
      "59\n",
      "104\n",
      "38\n",
      "38\n",
      "57\n",
      "43\n",
      "19\n",
      "227\n",
      "69\n",
      "16\n",
      "41\n",
      "67\n",
      "62\n",
      "56\n",
      "16\n",
      "255\n",
      "69\n",
      "29\n",
      "80\n",
      "85\n",
      "72\n",
      "27\n",
      "60\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "43\n",
      "58\n",
      "9\n",
      "No sob story, pizza just sounds delicious for dinner.\n",
      "39\n",
      "61\n",
      "44\n",
      "51\n",
      "108\n",
      "18\n",
      "90\n",
      "88\n",
      "14\n",
      "58\n",
      "68\n",
      "216\n",
      "20\n",
      "279\n",
      "184\n",
      "28\n",
      "112\n",
      "63\n",
      "114\n",
      "81\n",
      "96\n",
      "45\n",
      "64\n",
      "44\n",
      "7\n",
      "EDIT: Thanks DelicateCrush, I am very thankful. :)\n",
      "80\n",
      "115\n",
      "22\n",
      "50\n",
      "69\n",
      "82\n",
      "5\n",
      "I prefer saucy to cheesy.\n",
      "124\n",
      "76\n",
      "290\n",
      "193\n",
      "24\n",
      "594\n",
      "150\n",
      "135\n",
      "32\n",
      "50\n",
      "64\n",
      "56\n",
      "74\n",
      "15\n",
      "157\n",
      "1\n",
      "\n",
      "51\n",
      "224\n",
      "106\n",
      "33\n",
      "19\n",
      "81\n",
      "65\n",
      "30\n",
      "190\n",
      "232\n",
      "46\n",
      "122\n",
      "34\n",
      "48\n",
      "50\n",
      "90\n",
      "57\n",
      "136\n",
      "48\n",
      "115\n",
      "4\n",
      "cheese would be great.\n",
      "106\n",
      "147\n",
      "112\n",
      "82\n",
      "75\n",
      "30\n",
      "40\n",
      "59\n",
      "107\n",
      "31\n",
      "105\n",
      "72\n",
      "212\n",
      "17\n",
      "78\n",
      "67\n",
      "54\n",
      "66\n",
      "25\n",
      "66\n",
      "54\n",
      "582\n",
      "55\n",
      "97\n",
      "97\n",
      "45\n",
      "115\n",
      "88\n",
      "76\n",
      "79\n",
      "95\n",
      "66\n",
      "52\n",
      "14\n",
      "44\n",
      "100\n",
      "91\n",
      "143\n",
      "48\n",
      "37\n",
      "16\n",
      "46\n",
      "60\n",
      "205\n",
      "43\n",
      "129\n",
      "95\n",
      "66\n",
      "126\n",
      "148\n",
      "137\n",
      "52\n",
      "141\n",
      "50\n",
      "87\n",
      "24\n",
      "89\n",
      "107\n",
      "121\n",
      "60\n",
      "93\n",
      "24\n",
      "90\n",
      "129\n",
      "82\n",
      "93\n",
      "78\n",
      "88\n",
      "117\n",
      "104\n",
      "9\n",
      "pretty broke, n hungry.  Thanks if you can help!\n",
      "5\n",
      "Anyone?\n",
      "\n",
      "Will not return favor\n",
      "59\n",
      "62\n",
      "51\n",
      "164\n",
      "81\n",
      "94\n",
      "34\n",
      "71\n",
      "60\n",
      "58\n",
      "97\n",
      "117\n",
      "30\n",
      "486\n",
      "214\n",
      "125\n",
      "461\n",
      "62\n",
      "35\n",
      "62\n",
      "42\n",
      "30\n",
      "34\n",
      "102\n",
      "1\n",
      "\n",
      "23\n",
      "195\n",
      "121\n",
      "2\n",
      "Elkin, NC\n",
      "74\n",
      "56\n",
      "91\n",
      "21\n",
      "17\n",
      "61\n",
      "66\n",
      "39\n",
      "47\n",
      "30\n",
      "326\n",
      "28\n",
      "43\n",
      "76\n",
      "31\n",
      "27\n",
      "30\n",
      "124\n",
      "48\n",
      "27\n",
      "186\n",
      "66\n",
      "110\n",
      "38\n",
      "1\n",
      ".\n",
      "41\n",
      "34\n",
      "277\n",
      "107\n",
      "15\n",
      "1\n",
      "\n",
      "40\n",
      "89\n",
      "58\n",
      "83\n",
      "42\n",
      "48\n",
      "43\n",
      "28\n",
      "45\n",
      "99\n",
      "60\n",
      "141\n",
      "102\n",
      "49\n",
      "48\n",
      "70\n",
      "63\n",
      "12\n",
      "313\n",
      "31\n",
      "21\n",
      "46\n",
      "208\n",
      "173\n",
      "46\n",
      "308\n",
      "78\n",
      "52\n",
      "74\n",
      "62\n",
      "51\n",
      "25\n",
      "34\n",
      "120\n",
      "30\n",
      "1\n",
      "\n",
      "102\n",
      "3\n",
      "AMAA, first time.\n",
      "1\n",
      "\n",
      "77\n",
      "64\n",
      "38\n",
      "60\n",
      "24\n",
      "139\n",
      "155\n",
      "1\n",
      "\n",
      "61\n",
      "60\n",
      "4\n",
      "Any help would rule.\n",
      "35\n",
      "36\n",
      "257\n",
      "65\n",
      "35\n",
      "68\n",
      "9\n",
      "[Gimme Pizza!!!](http://www.youtube.com/watch?v=wusGIl3v044)\n",
      "177\n",
      "86\n",
      "120\n",
      "121\n",
      "54\n",
      "65\n",
      "20\n",
      "14\n",
      "63\n",
      "63\n",
      "30\n",
      "40\n",
      "137\n",
      "128\n",
      "66\n",
      "165\n",
      "194\n",
      "129\n",
      "63\n",
      "15\n",
      "141\n",
      "144\n",
      "28\n",
      "5\n",
      "no emergency just testing raop\n",
      "40\n",
      "47\n",
      "156\n",
      "69\n",
      "21\n",
      "86\n",
      "167\n",
      "1\n",
      "\n",
      "8\n",
      "Nothing too special. Just packing and craving pizza.\n",
      "47\n",
      "85\n",
      "1\n",
      "\n",
      "23\n",
      "58\n",
      "30\n",
      "39\n",
      "127\n",
      "48\n",
      "30\n",
      "65\n",
      "67\n",
      "163\n",
      "103\n",
      "51\n",
      "95\n",
      "186\n",
      "47\n",
      "70\n",
      "86\n",
      "37\n",
      "64\n",
      "8\n",
      "Not picky at all; anything is greatly appreciated. \n",
      "\n",
      "52\n",
      "67\n",
      "111\n",
      "26\n",
      "65\n",
      "194\n",
      "80\n",
      "28\n",
      "59\n",
      "64\n",
      "271\n",
      "55\n",
      "158\n",
      "36\n",
      "33\n",
      "17\n",
      "84\n",
      "21\n",
      "46\n",
      "36\n",
      "68\n",
      "64\n",
      "28\n",
      "58\n",
      "25\n",
      "52\n",
      "6\n",
      "In Fargo, ND if it matters\n",
      "41\n",
      "119\n",
      "26\n",
      "36\n",
      "6\n",
      "Any fellow hockey fans out there?\n",
      "109\n",
      "237\n",
      "62\n",
      "53\n",
      "502\n",
      "68\n",
      "22\n",
      "302\n",
      "92\n",
      "60\n",
      "176\n",
      "21\n",
      "65\n",
      "149\n",
      "227\n",
      "75\n",
      "39\n",
      "80\n",
      "247\n",
      "40\n",
      "193\n",
      "22\n",
      "119\n",
      "89\n",
      "57\n",
      "250\n",
      "19\n",
      "72\n",
      "37\n",
      "56\n",
      "256\n",
      "84\n",
      "47\n",
      "39\n",
      "99\n",
      "69\n",
      "103\n",
      "76\n",
      "67\n",
      "156\n",
      "94\n",
      "99\n",
      "44\n",
      "36\n",
      "34\n",
      "26\n",
      "1\n",
      "\n",
      "1\n",
      "\n",
      "34\n",
      "110\n",
      "60\n",
      "94\n",
      "37\n",
      "159\n",
      "228\n",
      "115\n",
      "5\n",
      "IDK what to write here.\n",
      "64\n",
      "53\n",
      "166\n",
      "96\n",
      "147\n",
      "34\n",
      "11\n",
      "32\n",
      "129\n",
      "32\n",
      "173\n",
      "146\n",
      "28\n",
      "11\n",
      "1\n",
      "\n",
      "62\n",
      "64\n",
      "20\n",
      "40\n",
      "161\n",
      "114\n",
      "18\n",
      "19\n",
      "24\n",
      "19\n",
      "79\n",
      "126\n",
      "55\n",
      "33\n",
      "39\n",
      "78\n",
      "66\n",
      "74\n",
      "21\n",
      "127\n",
      "105\n",
      "99\n",
      "77\n",
      "221\n",
      "34\n",
      "36\n",
      "38\n",
      "49\n",
      "45\n",
      "14\n",
      "1\n",
      "\n",
      "151\n",
      "80\n",
      "82\n",
      "151\n",
      "48\n",
      "84\n",
      "85\n",
      "70\n",
      "5\n",
      "My location is Dublin, Ireland. \n",
      "65\n",
      "2\n",
      "[US] ohio\n",
      "81\n",
      "75\n",
      "55\n",
      "228\n",
      "206\n",
      "57\n",
      "46\n",
      "18\n",
      "69\n",
      "49\n",
      "77\n",
      "49\n",
      "100\n",
      "4\n",
      "&amp;#3232;\\_&amp;#3232;\n",
      "\n",
      "32\n",
      "72\n",
      "41\n",
      "54\n",
      "49\n",
      "167\n",
      "48\n",
      "22\n",
      "65\n",
      "1\n",
      "\n",
      "73\n",
      "44\n",
      "1\n",
      "\n",
      "64\n",
      "69\n",
      "105\n",
      "59\n",
      "82\n",
      "62\n",
      "29\n",
      "112\n",
      "5\n",
      "That'd be pretty cool(:\n",
      "41\n",
      "82\n",
      "226\n",
      "77\n",
      "99\n",
      "88\n",
      "3\n",
      ":-) pizza sounds amazing\n",
      "269\n",
      "34\n",
      "71\n",
      "129\n",
      "13\n",
      "148\n",
      "27\n",
      "52\n",
      "77\n",
      "116\n",
      "120\n",
      "72\n",
      "17\n",
      "69\n",
      "82\n",
      "122\n",
      "81\n",
      "179\n",
      "70\n",
      "40\n",
      "37\n",
      "77\n",
      "47\n",
      "90\n",
      "108\n",
      "38\n",
      "54\n",
      "11\n",
      "51\n",
      "138\n",
      "128\n",
      "32\n",
      "209\n",
      "126\n",
      "40\n",
      "94\n",
      "159\n",
      "46\n",
      "183\n",
      "100\n",
      "21\n",
      "75\n",
      "62\n",
      "109\n",
      "85\n",
      "95\n",
      "88\n",
      "125\n",
      "134\n",
      "99\n",
      "40\n",
      "100\n",
      "57\n",
      "112\n",
      "5\n",
      "am i doing it right?\n",
      "82\n",
      "40\n",
      "82\n",
      "164\n",
      "85\n",
      "9\n",
      "I have a long shift today. And im hungry. \n",
      "103\n",
      "69\n",
      "104\n",
      "73\n",
      "75\n",
      "95\n",
      "112\n",
      "90\n",
      "158\n",
      "7\n",
      "Please sir, may I have some pie?\n",
      "188\n",
      "121\n",
      "65\n",
      "108\n",
      "115\n",
      "33\n",
      "16\n",
      "948\n",
      "37\n",
      "53\n",
      "414\n",
      "195\n",
      "193\n",
      "23\n",
      "250\n",
      "31\n",
      "47\n",
      "28\n",
      "57\n",
      "54\n",
      "44\n",
      "305\n",
      "41\n",
      "1\n",
      "\n",
      "56\n",
      "51\n",
      "10\n",
      "No food, no money, if anyone could be so kind.\n",
      "115\n",
      "43\n",
      "119\n",
      "36\n",
      "79\n",
      "63\n",
      "96\n",
      "209\n",
      "58\n",
      "43\n",
      "2\n",
      "In hungry,\n",
      "17\n",
      "27\n",
      "138\n"
     ]
    }
   ],
   "source": [
    "for text in X_train['request_text_edit_aware']:\n",
    "    RE = re.compile('[0-9a-z-]', re.I)\n",
    "    words = filter(lambda w: RE.search(w) and w.replace('-', ''), tokenizer.tokenize(text))\n",
    "    wordc = max(1, len(words))\n",
    "    print wordc\n",
    "    if wordc <= 10:\n",
    "        print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###MF pipeline\n",
    "# ptrn = r\"\\b(\"+ \"|\".join(moral_foundations[0]) + r\")\\b\"\n",
    "import functools\n",
    "from functools import partial\n",
    "\n",
    "##tokenizer to get the number of words in the sentence\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def apply_func(func, X, *args, **kwargs):\n",
    "    '''\n",
    "    Apply a function that applies to a single row to an entire matrix \n",
    "    \n",
    "    :param func: the function\n",
    "    :param X: the matrix\n",
    "    \n",
    "    :returns: a new matrix, where each row is the func applied to the rows of X\n",
    "    '''\n",
    "    func_ = partial(func, *args, **kwargs)\n",
    "    X_ = np.array([func_(i) for i in X])\n",
    "    return X_.reshape((len(X), np.prod(X_.shape)/len(X)))\n",
    "\n",
    "\n",
    "def get_scores(text, mf_label):\n",
    "    ###count number of words in the sentence\n",
    "    RE = re.compile('[0-9a-z-]', re.I)\n",
    "    words = filter(lambda w: RE.search(w) and w.replace('-', ''), tokenizer.tokenize(text))\n",
    "    wordc = max(1, len(words))\n",
    "    print wordc\n",
    "    \n",
    "    ###count number of matches with MF dict entries\n",
    "    ptrn = r\"\\b(\"+ \"|\".join(moral_foundations[mf_label]) + r\")\\b\"\n",
    "    str_ = \"safer safe safest something!\"\n",
    "    reg = re.compile(ptrn)\n",
    "    score = 0\n",
    "    for word in tokenizer.tokenize(str_):\n",
    "        score += len(reg.findall(word))\n",
    "\n",
    "    return float(score)/wordc\n",
    "\n",
    "class TextExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.vars]  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "\n",
    "class FunctionTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, the_function):\n",
    "        '''\n",
    "        Wrap a function into the transform method of a transformer.\n",
    "        \n",
    "        Use: \n",
    "            def plus_one(X):\n",
    "                return X+1\n",
    "            \n",
    "            f = FunctionTransformer(plus_one)\n",
    "            f.fit_transform(np.array([[1, 2, 3]]), [0, 0, 1])\n",
    "            Out[21]: array([[2, 3, 4]])        \n",
    "            \n",
    "        :param the_function: function that takes the matrix X as the first argument, \n",
    "            and outputs the desired transformed X \n",
    "        '''\n",
    "        self.the_function = the_function\n",
    "    def fit(self, *args, **kwargs):#does nothing at all\n",
    "        return self\n",
    "    def transform(self, X, **transform_params):\n",
    "        return self.the_function(X)\n",
    "\n",
    "\n",
    "\n",
    "##feature union\n",
    "features = []\n",
    "getMFTransformer1 = \n",
    "features.append(('mf', getMFTransformer))\n",
    "all_features = FeatureUnion(features)\n",
    "\n",
    "##scaling the features to make it stop executing bruh!\n",
    "source_scaler = StandardScaler(copy=False, with_mean=False, with_std=True)\n",
    "# source_scaler = MinMaxScaler()\n",
    "# MinMaxScaler\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('getText', TextExtractor('request_text_edit_aware')),\n",
    "                     ('all', all_features),\n",
    "                     ('scaler', source_scaler),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', MultinomialNB(alpha=0.1)),\n",
    "                    ('clf', linear_svc),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "print \"Fitting part 3!\"\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n",
    "# print \"NO!\"\n",
    "probas = text_clf.predict_proba(X_test)\n",
    "# print \"YO!\"\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=0)\n",
    "print precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# roc_auc = roc_auc_score(y_test, predicted)\n",
    "roc_auc = roc_auc_score(y_test, probas[:,1])\n",
    "print \"ROC = \", roc_auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test, predicted)\n",
    "#true negatives C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}\n",
    "tn = C[0][0]\n",
    "fn = C[1][0]\n",
    "tp = C[1][1]\n",
    "fp = C[0][1]\n",
    "##since labels are switched, invert the confusion matrix outputs: Pos = 0, Neg = 1\n",
    "#specificity = TN/TN+FP = tp/tp+fn\n",
    " \n",
    "print \"Specificity: \", float(tp)/(tp+fn)\n",
    "# print \"Precision: \", float(tn)/(tn+fn)\n",
    "# print \"Recall: \", float(tn)/(tn+fp)\n",
    "# print \"Accuracy: \", float(tn+tp)/(tn+tp+fp+fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
