{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import pandas as pd\n",
    "import json\n",
    "import codecs\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def read_dataset(path):\n",
    "  with codecs.open(path, 'r', 'utf-8') as myFile:\n",
    "    content = myFile.read()\n",
    "  dataset = json.loads(content)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5671\n",
      "Data loading and train-test splits = DONE!\n"
     ]
    }
   ],
   "source": [
    "###load JSON file\n",
    "file_name = 'data/pizza_request_dataset.json'\n",
    "dataset = read_dataset(file_name)\n",
    "df = pd.read_json(json.dumps(dataset, sort_keys=True, indent=2))\n",
    "\n",
    "###create random 90-10 split\n",
    "X = df\n",
    "print len(X)\n",
    "\n",
    "rows = random.sample(X.index, int(0.9*len(X)) + 1)\n",
    "X_train = X.ix[rows]\n",
    "X_test = X.drop(rows)\n",
    "y_train = X_train.requester_received_pizza.astype(int)\n",
    "y_test = X_test.requester_received_pizza.astype(int)\n",
    "\n",
    "print \"Data loading and train-test splits = DONE!\"\n",
    "###\n",
    "\n",
    "###subsample data\n",
    "# print \"Subsampling\"\n",
    "# subsample = 30\n",
    "# X_train, y_train, X_test, y_test = X_train[:subsample], y_train[:subsample], X_test[:subsample], y_test[:subsample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 1\n"
     ]
    }
   ],
   "source": [
    "print \"part 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting part 1!\n",
      "0.362831858407 0.347457627119 0.354978354978 0.73721340388\n",
      "ROC =  0.614133101808\n",
      "Specificity:  0.839643652561\n"
     ]
    }
   ],
   "source": [
    "###Model 1 - a) n-grams\n",
    "\n",
    "### build pipeline; fit train; predict on test\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "##vectorizer arguments blah!\n",
    "\n",
    "tokenizer=None#word_tokenize\n",
    "# stop_words=nltk.corpus.stopwords.words(\"english\")#None\n",
    "ngram_range=(1, 2)\n",
    "lowercase=True\n",
    "max_features=500\n",
    "binary=False\n",
    "dtype=np.float64\n",
    "\n",
    "class TextExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.vars]  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "\n",
    "###create unigram vectorizer\n",
    "uniVect = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(1,1),\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=max_features)\n",
    "\n",
    "###create bigram vect\n",
    "biVect = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(2,2),\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=max_features)\n",
    "\n",
    "# load custom features and FeatureUnion with Vectorizer\n",
    "features = []\n",
    "features.append(('unigram', uniVect))\n",
    "features.append(('bigram', biVect))\n",
    "all_features = FeatureUnion(features)\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear', probability=True, class_weight='balanced')\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('getText', TextExtractor('request_text_edit_aware')),\n",
    "                     ('all', all_features),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', linear_svc),\n",
    "                    ('clf', MultinomialNB(alpha=0.1)),\n",
    "\n",
    "                    ])\n",
    "\n",
    "# text_clf = Pipeline([\n",
    "#                      ('vect', vectorizer),\n",
    "# #                      ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', linear_svc),\n",
    "#                     ])\n",
    "\n",
    "###fit training data\n",
    "print \"Fitting part 1!\"\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n",
    "# print \"NO!\"\n",
    "probas = text_clf.predict_proba(X_test)\n",
    "# print \"YO!\"\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=1)\n",
    "print precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# roc_auc = roc_auc_score(y_test, predicted)\n",
    "roc_auc = roc_auc_score(y_test, probas[:,1])\n",
    "print \"ROC = \", roc_auc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test, predicted)\n",
    "#true negatives C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}\n",
    "tn = C[0][0]\n",
    "fn = C[1][0]\n",
    "tp = C[1][1]\n",
    "fp = C[0][1]\n",
    "##since labels are switched, invert the confusion matrix outputs: Pos = 0, Neg = 1\n",
    "#specificity = TN/TN+FP = tp/tp+fn\n",
    " \n",
    "print \"Specificity: \", float(tn)/(tn+fp)\n",
    "# print \"Precision: \", float(tn)/(tn+fn)\n",
    "# print \"Recall: \", float(tn)/(tn+fp)\n",
    "# print \"Accuracy: \", float(tn+tp)/(tn+tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 2\n"
     ]
    }
   ],
   "source": [
    "print \"part 2\"\n",
    "# 0.8125 0.854875283447 0.833149171271 0.733686067019\n",
    "# ROC =  0.563033149768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting part 2!\n",
      "0.327485380117 0.474576271186 0.387543252595 0.687830687831\n",
      "ROC =  0.614133101808\n",
      "Specificity:  0.743875278396\n"
     ]
    }
   ],
   "source": [
    "###Model 2 - a) custom features\n",
    "\n",
    "### build pipeline; fit train; predict on test\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing.data import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "class ColumnExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.vars]  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "    \n",
    "class StringExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.vars].astype(str)  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "    \n",
    "class SubredditExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.vars].apply(lambda x: ' '.join(x))  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "\n",
    "##vectorizer arguments blah!\n",
    "tokenizer=None#word_tokenize\n",
    "# stop_words=nltk.corpus.stopwords.words(\"english\")#None\n",
    "ngram_range=(1, 1)\n",
    "lowercase=True\n",
    "max_features=10000\n",
    "binary=False\n",
    "dtype=np.float64\n",
    "###create unigram vectorizer\n",
    "subVect = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=ngram_range,\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=max_features)\n",
    "\n",
    "flairVect = CountVectorizer(decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=ngram_range,\n",
    "                               lowercase=lowercase,\n",
    "                               binary=binary,\n",
    "                               dtype=dtype,\n",
    "                               max_features=100)\n",
    "\n",
    "# load custom features for FeatureUnion\n",
    "cols_act = [\n",
    "'post_was_edited',\n",
    "'requester_account_age_in_days_at_request',\n",
    "'requester_account_age_in_days_at_retrieval',\n",
    "'requester_days_since_first_post_on_raop_at_request',\n",
    "'requester_days_since_first_post_on_raop_at_retrieval',\n",
    "'requester_number_of_comments_at_request',\n",
    "'requester_number_of_comments_at_retrieval',\n",
    "'requester_number_of_comments_in_raop_at_request',\n",
    "'requester_number_of_comments_in_raop_at_retrieval',\n",
    "'requester_number_of_posts_at_request',\n",
    "'requester_number_of_posts_at_retrieval',\n",
    "'requester_number_of_posts_on_raop_at_request',\n",
    "'requester_number_of_posts_on_raop_at_retrieval',\n",
    "'requester_number_of_subreddits_at_request',\n",
    "# 'requester_subreddits_at_request',\n",
    "]\n",
    "\n",
    "cols_rep = [\n",
    "'number_of_downvotes_of_request_at_retrieval',\n",
    "'number_of_upvotes_of_request_at_retrieval',\n",
    "'requester_upvotes_minus_downvotes_at_request', ###this contains negative values\n",
    "'requester_upvotes_minus_downvotes_at_retrieval',###this contains negative values\n",
    "'requester_upvotes_plus_downvotes_at_request',\n",
    "'requester_upvotes_plus_downvotes_at_retrieval',\n",
    "### 'requester_user_flair',\n",
    "]\n",
    "\n",
    "get_flair = Pipeline([\n",
    "                     ('getFlair', StringExtractor('requester_user_flair')),\n",
    "                     ('counts', flairVect),\n",
    "                    ])\n",
    "\n",
    "get_subs = Pipeline([\n",
    "                     ('getSubs', SubredditExtractor('requester_subreddits_at_request')),\n",
    "                     ('counts', subVect),\n",
    "                    ])\n",
    "##feature union\n",
    "features = []\n",
    "features.append(('activity', ColumnExtractor(cols_act)))\n",
    "features.append(('reputation', ColumnExtractor(cols_rep) ))\n",
    "# features.append(('flair', get_flair))\n",
    "features.append(('subs', get_subs))\n",
    "\n",
    "all_features = FeatureUnion(features)\n",
    "\n",
    "##scaling the features to make it stop executing bruh!\n",
    "source_scaler = StandardScaler(copy=False, with_mean=False, with_std=True)\n",
    "# source_scaler = MinMaxScaler()\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear', probability=True, class_weight='balanced')\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "#                      ('getText', TextExtractor('request_text_edit_aware')),\n",
    "                     ('all', all_features),\n",
    "                    ('scaler', source_scaler),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', LinearSVC(C=0.1)),\n",
    "#                     ('clf', MultinomialNB(alpha=0.1)),\n",
    "                    ('clf', linear_svc),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "print \"Fitting part 2!\"\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n",
    "# print \"NO!\"\n",
    "# probas = text_clf.predict_proba(X_test)\n",
    "# print \"YO!\"\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=1)\n",
    "print precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "#### roc_auc = roc_auc_score(y_test, predicted)\n",
    "roc_auc = roc_auc_score(y_test, probas[:,1])\n",
    "print \"ROC = \", roc_auc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test, predicted)\n",
    "#true negatives C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}\n",
    "tn = C[0][0]\n",
    "fn = C[1][0]\n",
    "tp = C[1][1]\n",
    "fp = C[0][1]\n",
    "##since labels are switched, invert the confusion matrix outputs: Pos = 0, Neg = 1\n",
    "#specificity = TN/TN+FP = tp/tp+fn\n",
    " \n",
    "print \"Specificity: \", float(tn)/(tn+fp)\n",
    "# print \"Precision: \", float(tn)/(tn+fn)\n",
    "# print \"Recall: \", float(tn)/(tn+fp)\n",
    "# print \"Accuracy: \", float(tn+tp)/(tn+tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test, predicted)\n",
    "#true negatives C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}\n",
    "tn = C[0][0]\n",
    "fn = C[1][0]\n",
    "tp = C[1][1]\n",
    "fp = C[0][1]\n",
    "##since labels are switched, invert the confusion matrix outputs: Pos = 0, Neg = 1\n",
    "#specificity = TN/TN+FP = tp/tp+fn\n",
    " \n",
    "print \"Specificity: \", float(tn)/(tn+fp)\n",
    "# print \"Precision: \", float(tn)/(tn+fn)\n",
    "# print \"Recall: \", float(tn)/(tn+fp)\n",
    "# print \"Accuracy: \", float(tn+tp)/(tn+tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8361"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flairVect.vocabulary_\n",
    "len(subVect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 3: Narratives\n",
      "Running in 4687.pts-33.flashmob03\n"
     ]
    }
   ],
   "source": [
    "print 'part 3: Narratives'\n",
    "print \"Running in 4687.pts-33.flashmob03\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting part 3 (alternative: Using count vectorizer)!\n",
      "0.273885350318 0.364406779661 0.312727272727 0.666666666667\n",
      "ROC =  0.599845230456\n",
      "Specificity:  0.746102449889\n"
     ]
    }
   ],
   "source": [
    "##vectorizer arguments blah!\n",
    "tokenizer=None#word_tokenize\n",
    "# stop_words=nltk.corpus.stopwords.words(\"english\")#None\n",
    "ngram_range=(1, 1)\n",
    "lowercase=True\n",
    "max_features=None\n",
    "binary=False\n",
    "dtype=np.float64\n",
    "\n",
    "desire_vocab = pd.read_csv('resources/narratives/desire.txt', names = [\"words\"])\n",
    "###create unigram vectorizer for desire features\n",
    "desireVect = CountVectorizer(\n",
    "                               vocabulary = desire_vocab.words,\n",
    "                               decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(1,1),\n",
    "                               lowercase=lowercase,\n",
    "#                                binary=binary,\n",
    "                               dtype=dtype,\n",
    "#                                max_features=max_features\n",
    "                            )\n",
    "\n",
    "family_vocab = pd.read_csv('resources/narratives/family.txt', names = [\"words\"])\n",
    "###create unigram vectorizer for family_vocab features\n",
    "familyVect = CountVectorizer(\n",
    "                               vocabulary = family_vocab.words,\n",
    "                               decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(1,1),\n",
    "                               lowercase=lowercase,\n",
    "#                                binary=binary,\n",
    "                               dtype=dtype,\n",
    "#                                max_features=max_features\n",
    "                            )\n",
    "\n",
    "job_vocab = pd.read_csv('resources/narratives/job.txt', names = [\"words\"])\n",
    "###create unigram vectorizer for job_vocab features\n",
    "jobVect = CountVectorizer(\n",
    "                               vocabulary = job_vocab.words,\n",
    "                               decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(1,1),\n",
    "                               lowercase=lowercase,\n",
    "#                                binary=binary,\n",
    "                               dtype=dtype,\n",
    "#                                max_features=max_features\n",
    "                            )\n",
    "\n",
    "money_vocab = pd.read_csv('resources/narratives/money.txt', names = [\"words\"])\n",
    "###create unigram vectorizer for money_vocab features\n",
    "###note that this list contains duplicate terms: bills, due\n",
    "moneyVect = CountVectorizer(\n",
    "                               vocabulary = money_vocab.words,\n",
    "                               decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(1,1),\n",
    "                               lowercase=lowercase,\n",
    "#                                binary=binary,\n",
    "                               dtype=dtype,\n",
    "#                                max_features=max_features\n",
    "                            )\n",
    "\n",
    "student_vocab = pd.read_csv('resources/narratives/student.txt', names = [\"words\"])\n",
    "###create unigram vectorizer for student features\n",
    "studentVect = CountVectorizer(\n",
    "                               vocabulary = student_vocab.words,\n",
    "                               decode_error=\"ignore\",\n",
    "#                                tokenizer=tokenizer,\n",
    "#                                stop_words=stop_words,\n",
    "                               ngram_range=(1,1),\n",
    "                               lowercase=lowercase,\n",
    "#                                binary=binary,\n",
    "                               dtype=dtype,\n",
    "#                                max_features=max_features\n",
    "                            )\n",
    "\n",
    "\n",
    "##feature union\n",
    "features = []\n",
    "features.append(('desire', desireVect))\n",
    "features.append(('family', familyVect))\n",
    "features.append(('job', jobVect))\n",
    "features.append(('money', moneyVect))\n",
    "features.append(('student', studentVect))\n",
    "all_features = FeatureUnion(features)\n",
    "\n",
    "##scaling the features to make it stop executing bruh!\n",
    "source_scaler = StandardScaler(copy=False, with_mean=False, with_std=True)\n",
    "# source_scaler = MinMaxScaler()\n",
    "# MinMaxScaler\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear', probability=True, class_weight='balanced')\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('getText', TextExtractor('request_text_edit_aware')),\n",
    "                     ('all', all_features),\n",
    "                     ('scaler', source_scaler),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', MultinomialNB(alpha=0.1)),\n",
    "                    ('clf', linear_svc),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "print \"Fitting part 3 (alternative: Using count vectorizer)!\"\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n",
    "# print \"NO!\"\n",
    "probas = text_clf.predict_proba(X_test)\n",
    "# print \"YO!\"\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=1)\n",
    "print precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# roc_auc = roc_auc_score(y_test, predicted)\n",
    "roc_auc = roc_auc_score(y_test, probas[:,1])\n",
    "print \"ROC = \", roc_auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test, predicted)\n",
    "#true negatives C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}\n",
    "tn = C[0][0]\n",
    "fn = C[1][0]\n",
    "tp = C[1][1]\n",
    "fp = C[0][1]\n",
    "##since labels are switched, invert the confusion matrix outputs: Pos = 0, Neg = 1\n",
    "#specificity = TN/TN+FP = tp/tp+fn\n",
    " \n",
    "print \"Specificity: \", float(tn)/(tn+fp)\n",
    "# print \"Precision: \", float(tn)/(tn+fn)\n",
    "# print \"Recall: \", float(tn)/(tn+fp)\n",
    "# print \"Accuracy: \", float(tn+tp)/(tn+tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 4: Moral foundations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"part 4: Moral foundations\"\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Moral Foundations dict\n"
     ]
    }
   ],
   "source": [
    "###parse the dictionary bro\n",
    "with open('resources/MoralFoundations.dic', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "count = 0\n",
    "l = 0\n",
    "\n",
    "##tokenizer to get the number of words in the sentence\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "##\n",
    "# list = [][]\n",
    "list_1 = []\n",
    "list_2 = []\n",
    "list_3 = []\n",
    "list_4 = []\n",
    "list_5 = []\n",
    "list_6 = []\n",
    "list_7 = []\n",
    "list_8 = []\n",
    "list_9 = []\n",
    "list_10 = []\n",
    "list_11 = []\n",
    "\n",
    "print \"Parsing Moral Foundations dict\"\n",
    "for line in lines:\n",
    "    if \"%\" in line:\n",
    "        count +=1 \n",
    "#         print line\n",
    "        continue\n",
    "    if count < 2:\n",
    "        continue\n",
    "    first = 0\n",
    "    for word in tokenizer.tokenize(line):\n",
    "#         print word\n",
    "        if first == 0:\n",
    "            if \"*\" in line:\n",
    "                word = word + \".*\"\n",
    "            term = word\n",
    "#             print \"Word: \", term\n",
    "        \n",
    "        if first > 0:\n",
    "            label = int(word)\n",
    "#             print \"Label: \", label\n",
    "            if label == 1:\n",
    "                list_1.append(term)\n",
    "            elif label == 2:\n",
    "                list_2.append(term)\n",
    "            elif label == 3:\n",
    "                list_3.append(term)\n",
    "            elif label == 4:\n",
    "                list_4.append(term)\n",
    "            elif label == 5:\n",
    "                list_5.append(term)\n",
    "            elif label == 6:\n",
    "                list_6.append(term)\n",
    "            elif label == 7:\n",
    "                list_7.append(term)\n",
    "            elif label == 8:\n",
    "                list_8.append(term)\n",
    "            elif label == 9:\n",
    "                list_9.append(term)\n",
    "            elif label == 10:\n",
    "                list_10.append(term)\n",
    "            elif label == 11:\n",
    "                list_11.append(term)\n",
    "        first += 1\n",
    "#     print \"---\"\n",
    "    l+= 1\n",
    "# print \"Lines done = \", l\n",
    "moral_foundations = []\n",
    "moral_foundations.append(list_1)\n",
    "moral_foundations.append(list_2)\n",
    "moral_foundations.append(list_3)\n",
    "moral_foundations.append(list_4)\n",
    "moral_foundations.append(list_5)\n",
    "moral_foundations.append(list_6)\n",
    "moral_foundations.append(list_7)\n",
    "moral_foundations.append(list_8)\n",
    "moral_foundations.append(list_9)\n",
    "moral_foundations.append(list_10)\n",
    "moral_foundations.append(list_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moral_foundations[10]\n",
    "# postbanhate_iter += np.sum(arr)\n",
    "# for text in df1.body:\n",
    "#     prebanWords_iter += len(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting part 4!\n",
      "0.175 0.0593220338983 0.0886075949367 0.746031746032\n",
      "ROC =  0.485693254313\n",
      "Specificity:  0.926503340757\n"
     ]
    }
   ],
   "source": [
    "# ptrn = r\"\\b(\"+ \"|\".join(moral_foundations[0]) + r\")\\b\"\n",
    "import functools\n",
    "from functools import partial\n",
    "\n",
    "##tokenizer to get the number of words in the sentence\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def apply_func(func, X, *args, **kwargs):\n",
    "    '''\n",
    "    Apply a function that applies to a single row to an entire matrix \n",
    "    \n",
    "    :param func: the function\n",
    "    :param X: the matrix\n",
    "    \n",
    "    :returns: a new matrix, where each row is the func applied to the rows of X\n",
    "    '''\n",
    "    func_ = partial(func, *args, **kwargs)\n",
    "    X_ = np.array([func_(i) for i in X])\n",
    "    return X_.reshape((len(X), np.prod(X_.shape)/len(X)))\n",
    "\n",
    "\n",
    "def get_scores(text, mf_label):\n",
    "    ###count number of words in the sentence\n",
    "    RE = re.compile('[0-9a-z-]', re.I)\n",
    "    words = filter(lambda w: RE.search(w) and w.replace('-', ''), tokenizer.tokenize(text))\n",
    "    wordc = max(1, len(words))\n",
    "#     print wordc\n",
    "    \n",
    "    ###count number of matches with MF dict entries\n",
    "    ptrn = r\"\\b(\"+ \"|\".join(moral_foundations[mf_label]) + r\")\\b\"\n",
    "    reg = re.compile(ptrn)\n",
    "    score = 0\n",
    "    for word in tokenizer.tokenize(text):\n",
    "        score += len(reg.findall(word))\n",
    "#     print float(score)/wordc\n",
    "    return float(score)/wordc\n",
    "\n",
    "class TextExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.vars]  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "\n",
    "class FunctionTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, the_function):\n",
    "        '''\n",
    "        Wrap a function into the transform method of a transformer.\n",
    "        \n",
    "        Use: \n",
    "            def plus_one(X):\n",
    "                return X+1\n",
    "            \n",
    "            f = FunctionTransformer(plus_one)\n",
    "            f.fit_transform(np.array([[1, 2, 3]]), [0, 0, 1])\n",
    "            Out[21]: array([[2, 3, 4]])        \n",
    "            \n",
    "        :param the_function: function that takes the matrix X as the first argument, \n",
    "            and outputs the desired transformed X \n",
    "        '''\n",
    "        self.the_function = the_function\n",
    "    def fit(self, *args, **kwargs):#does nothing at all\n",
    "        return self\n",
    "    def transform(self, X, **transform_params):\n",
    "        return self.the_function(X)\n",
    "\n",
    "##feature union\n",
    "features = []\n",
    "# getMFTransformer = FunctionTransformer(partial(apply_func, get_scores, mf_label=0))\n",
    "# features.append(('mf'+str(0),getMFTransformer))\n",
    "start = 0 \n",
    "end = 11\n",
    "for i in range(start,end):\n",
    "#     print i\n",
    "#     getMFTransformer = FunctionTransformer(partial(apply_func, get_scores, mf_label=0))\n",
    "    features.append(('mf'+str(i), FunctionTransformer(partial(apply_func, get_scores, mf_label=i))))\n",
    "\n",
    "all_features = FeatureUnion(features)\n",
    "##scaling the features to make it stop executing bruh!\n",
    "source_scaler = StandardScaler(copy=False, with_mean=False, with_std=True)\n",
    "# source_scaler = MinMaxScaler()\n",
    "# MinMaxScaler\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear', probability=True, class_weight='balanced')\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('getText', TextExtractor('request_text_edit_aware')),\n",
    "                     ('all', all_features),\n",
    "                     ('scaler', source_scaler),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', MultinomialNB(alpha=0.1)),\n",
    "                    ('clf', linear_svc),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "print \"Fitting part 4!\"\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n",
    "# print \"NO!\"\n",
    "probas = text_clf.predict_proba(X_test)\n",
    "# print \"YO!\"\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=1)\n",
    "print precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# roc_auc = roc_auc_score(y_test, predicted)\n",
    "roc_auc = roc_auc_score(y_test, probas[:,1])\n",
    "print \"ROC = \", roc_auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test, predicted)\n",
    "#true negatives C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}\n",
    "tn = C[0][0]\n",
    "fn = C[1][0]\n",
    "tp = C[1][1]\n",
    "fp = C[0][1]\n",
    "##since labels are switched, invert the confusion matrix outputs: Pos = 0, Neg = 1\n",
    "#specificity = TN/TN+FP = tp/tp+fn\n",
    " \n",
    "print \"Specificity: \", float(tn)/(tn+fp)\n",
    "# print \"Precision: \", float(tn)/(tn+fn)\n",
    "# print \"Recall: \", float(tn)/(tn+fp)\n",
    "# print \"Accuracy: \", float(tn+tp)/(tn+tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptrn = r\"\\b(\"+ \"|\".join(moral_foundations[10]) + r\")\\b\"\n",
    "# str_ = \"safelexs ethical safe safest something!\"\n",
    "\n",
    "# reg = re.compile(ptrn)\n",
    "# score = 0\n",
    "\n",
    "# for word in tokenizer.tokenize(str_):\n",
    "#     score += len(reg.findall(word))\n",
    "\n",
    "# print score\n",
    "# #     print len(reg.match(str_).group())\n",
    "# # if re.compile(ptrn).match(str_).group() == None:\n",
    "# #     print \"No match\"\n",
    "\n",
    "# for text in X_train['request_text_edit_aware']:\n",
    "#     RE = re.compile('[0-9a-z-]', re.I)\n",
    "#     words = filter(lambda w: RE.search(w) and w.replace('-', ''), tokenizer.tokenize(text))\n",
    "#     wordc = max(1, len(words))\n",
    "#     print wordc\n",
    "#     if wordc <= 10:\n",
    "#         print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "###part 3 Regex Matching: \n",
    "liwc = []\n",
    "liwc.append(pd.read_csv('resources/narratives/desire.txt', names = [\"words\"]).words)\n",
    "liwc.append(pd.read_csv('resources/narratives/family.txt', names = [\"words\"]).words)\n",
    "liwc.append(pd.read_csv('resources/narratives/job.txt', names = [\"words\"]).words)\n",
    "liwc.append(pd.read_csv('resources/narratives/money.txt', names = [\"words\"]).words)\n",
    "liwc.append(pd.read_csv('resources/narratives/student.txt', names = [\"words\"]).words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting part 3!\n",
      "0.0 0.0 0.0 0.79012345679\n",
      "ROC =  0.541240421275\n",
      "Specificity:  0.997772828508\n"
     ]
    }
   ],
   "source": [
    "# ptrn = r\"\\b(\"+ \"|\".join(moral_foundations[0]) + r\")\\b\"\n",
    "import functools\n",
    "from functools import partial\n",
    "\n",
    "##tokenizer to get the number of words in the sentence\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def apply_func(func, X, *args, **kwargs):\n",
    "    '''\n",
    "    Apply a function that applies to a single row to an entire matrix \n",
    "    \n",
    "    :param func: the function\n",
    "    :param X: the matrix\n",
    "    \n",
    "    :returns: a new matrix, where each row is the func applied to the rows of X\n",
    "    '''\n",
    "    func_ = partial(func, *args, **kwargs)\n",
    "    X_ = np.array([func_(i) for i in X])\n",
    "    return X_.reshape((len(X), np.prod(X_.shape)/len(X)))\n",
    "\n",
    "\n",
    "def get_narrative_scores(text, label):\n",
    "    ###count number of words in the sentence\n",
    "    RE = re.compile('[0-9a-z-]', re.I)\n",
    "    words = filter(lambda w: RE.search(w) and w.replace('-', ''), tokenizer.tokenize(text))\n",
    "    wordc = max(1, len(words))\n",
    "#     print wordc\n",
    "    \n",
    "    ###count number of matches with MF dict entries\n",
    "    ptrn = r\"\\b(\"+ \"|\".join(liwc[label]) + r\")\\b\"\n",
    "    reg = re.compile(ptrn)\n",
    "    score = 0\n",
    "    for word in tokenizer.tokenize(text):\n",
    "        score += len(reg.findall(word))\n",
    "#     print float(score)/wordc\n",
    "    return float(score)/wordc\n",
    "\n",
    "class TextExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, vars):\n",
    "        self.vars = vars  # e.g. pass in a column name to extract\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.vars]  # where the actual feature extraction happens\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # generally does nothing\n",
    "\n",
    "class FunctionTransformer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, the_function):\n",
    "        '''\n",
    "        Wrap a function into the transform method of a transformer.\n",
    "        \n",
    "        Use: \n",
    "            def plus_one(X):\n",
    "                return X+1\n",
    "            \n",
    "            f = FunctionTransformer(plus_one)\n",
    "            f.fit_transform(np.array([[1, 2, 3]]), [0, 0, 1])\n",
    "            Out[21]: array([[2, 3, 4]])        \n",
    "            \n",
    "        :param the_function: function that takes the matrix X as the first argument, \n",
    "            and outputs the desired transformed X \n",
    "        '''\n",
    "        self.the_function = the_function\n",
    "    def fit(self, *args, **kwargs):#does nothing at all\n",
    "        return self\n",
    "    def transform(self, X, **transform_params):\n",
    "        return self.the_function(X)\n",
    "\n",
    "##feature union\n",
    "features = []\n",
    "# getMFTransformer = FunctionTransformer(partial(apply_func, get_scores, mf_label=0))\n",
    "# features.append(('mf'+str(0),getMFTransformer))\n",
    "start = 0 \n",
    "end = 5\n",
    "for i in range(start,end):\n",
    "#     print i8\n",
    "#     getMFTransformer = FunctionTransformer(partial(apply_func, get_scores, mf_label=0))\n",
    "    features.append(('nr'+str(i), FunctionTransformer(partial(apply_func, get_narrative_scores, label=i))))\n",
    "\n",
    "all_features = FeatureUnion(features)\n",
    "##scaling the features to make it stop executing bruh!\n",
    "source_scaler = StandardScaler(copy=False, with_mean=False, with_std=True)\n",
    "# source_scaler = MinMaxScaler()\n",
    "# MinMaxScaler\n",
    "\n",
    "linear_svc = svm.SVC(kernel='linear', probability=True)\n",
    "\n",
    "###create pipeline\n",
    "text_clf = Pipeline([\n",
    "                     ('getText', TextExtractor('request_text_edit_aware')),\n",
    "                     ('all', all_features),\n",
    "                     ('scaler', source_scaler),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', MultinomialNB(alpha=0.1)),\n",
    "#                     ('clf', linear_svc),\n",
    "                    ])\n",
    "\n",
    "###fit training data\n",
    "print \"Fitting part 3!\"\n",
    "text_clf = text_clf.fit(X_train, y_train)\n",
    "\n",
    "### predict on test data\n",
    "predicted = text_clf.predict(X_test)\n",
    "np.mean(predicted == y_test)\n",
    "# print \"NO!\"\n",
    "probas = text_clf.predict_proba(X_test)\n",
    "# print \"YO!\"\n",
    "###get performance metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "accuracy = accuracy_score(y_test,predicted)\n",
    "#         accuracy = np.mean(y_CVtest == predicted)\n",
    "precision, recall, fscore, sup = precision_recall_fscore_support(y_test, predicted, average='binary', pos_label=1)\n",
    "print precision, recall, fscore, accuracy# np.mean(predicted == y_test)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# roc_auc = roc_auc_score(y_test, predicted)\n",
    "roc_auc = roc_auc_score(y_test, probas[:,1])\n",
    "print \"ROC = \", roc_auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "C = confusion_matrix(y_test, predicted)\n",
    "#true negatives C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}\n",
    "tn = C[0][0]\n",
    "fn = C[1][0]\n",
    "tp = C[1][1]\n",
    "fp = C[0][1]\n",
    "##since labels are switched, invert the confusion matrix outputs: Pos = 0, Neg = 1\n",
    "#specificity = TN/TN+FP = tp/tp+fn\n",
    " \n",
    "print \"Specificity: \", float(tn)/(tn+fp)\n",
    "# print \"Precision: \", float(tn)/(tn+fn)\n",
    "# print \"Recall: \", float(tn)/(tn+fp)\n",
    "# print \"Accuracy: \", float(tn+tp)/(tn+tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
